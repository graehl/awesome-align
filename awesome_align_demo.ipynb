{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c7bb3938fb3c4b1ba8644281707b949e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b08434187a1e40cb9d0d1bc3c741eb8f",
              "IPY_MODEL_bfafb1da053444898ca8c9043a282c65",
              "IPY_MODEL_6d63e6ecdb024023a5f51f269a64da4a"
            ],
            "layout": "IPY_MODEL_1437c350de72407ea76bc7bfd61f3e90"
          }
        },
        "b08434187a1e40cb9d0d1bc3c741eb8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53b9bc01c1b449bb8720b376c886bfff",
            "placeholder": "​",
            "style": "IPY_MODEL_e907e85bbc084d53bc66e7bb985702b9",
            "value": "Downloading: 100%"
          }
        },
        "bfafb1da053444898ca8c9043a282c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e824fdbccd6494e9d367db8817324ac",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af4838cd53a24c2390d2fd5389dd3a0e",
            "value": 625
          }
        },
        "6d63e6ecdb024023a5f51f269a64da4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25b3f55ce941496b9f743e82572bc593",
            "placeholder": "​",
            "style": "IPY_MODEL_0f0c48d26444490fb86d0bb526d6195b",
            "value": " 625/625 [00:00&lt;00:00, 26.2kB/s]"
          }
        },
        "1437c350de72407ea76bc7bfd61f3e90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53b9bc01c1b449bb8720b376c886bfff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e907e85bbc084d53bc66e7bb985702b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e824fdbccd6494e9d367db8817324ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af4838cd53a24c2390d2fd5389dd3a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25b3f55ce941496b9f743e82572bc593": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f0c48d26444490fb86d0bb526d6195b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02abfcba05ec4c94b9be0e0b5bf95b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27fc060b99a246398dbd0178a8d2bf1f",
              "IPY_MODEL_b5760e6d9a70497781b272dc6acf775e",
              "IPY_MODEL_84bd4564ac304147be7f455c7a42708f"
            ],
            "layout": "IPY_MODEL_56be3e22669b465596b8c638899d1673"
          }
        },
        "27fc060b99a246398dbd0178a8d2bf1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_387c549af19b4903bad9d45156d9ce4e",
            "placeholder": "​",
            "style": "IPY_MODEL_594a312a75e44b609134f53a89c73bca",
            "value": "Downloading: 100%"
          }
        },
        "b5760e6d9a70497781b272dc6acf775e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39cf1202822049718fd10f9b22e4c1ca",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_388e3617b2fe4784bddb23217d985db4",
            "value": 995526
          }
        },
        "84bd4564ac304147be7f455c7a42708f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92ef1ef592c14c9a93814fa501fac4cb",
            "placeholder": "​",
            "style": "IPY_MODEL_5d0f8abf22e647aea935ab5a53789869",
            "value": " 996k/996k [00:00&lt;00:00, 2.55MB/s]"
          }
        },
        "56be3e22669b465596b8c638899d1673": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "387c549af19b4903bad9d45156d9ce4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "594a312a75e44b609134f53a89c73bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39cf1202822049718fd10f9b22e4c1ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "388e3617b2fe4784bddb23217d985db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92ef1ef592c14c9a93814fa501fac4cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d0f8abf22e647aea935ab5a53789869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f581f4aba2345e3b969d117cfb642bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a4653d010d1476fb18da6017b8cdc4b",
              "IPY_MODEL_dfad1e1b35a649d0a7dc11f95a05d2a9",
              "IPY_MODEL_76aae583d0c9411dbcd893505683e268"
            ],
            "layout": "IPY_MODEL_1bb6e20b43034864bd829d1393b6a961"
          }
        },
        "9a4653d010d1476fb18da6017b8cdc4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19d90e36cd1544f288eaf211199b3976",
            "placeholder": "​",
            "style": "IPY_MODEL_dc17299e2d2d44598ed2e97d65cba45a",
            "value": "Downloading: 100%"
          }
        },
        "dfad1e1b35a649d0a7dc11f95a05d2a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ff8fe2dd1da46178628bd084d10a89f",
            "max": 714314041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8ce2ac810d44b2c8c80058a412719d2",
            "value": 714314041
          }
        },
        "76aae583d0c9411dbcd893505683e268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f29de119e05641feb091134eb6fb2a82",
            "placeholder": "​",
            "style": "IPY_MODEL_b06e9f9e74b74758a4f4939a0b661f8c",
            "value": " 714M/714M [00:15&lt;00:00, 47.3MB/s]"
          }
        },
        "1bb6e20b43034864bd829d1393b6a961": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19d90e36cd1544f288eaf211199b3976": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc17299e2d2d44598ed2e97d65cba45a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ff8fe2dd1da46178628bd084d10a89f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8ce2ac810d44b2c8c80058a412719d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f29de119e05641feb091134eb6fb2a82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b06e9f9e74b74758a4f4939a0b661f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graehl/awesome-align/blob/master/awesome_align_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hjc7LvIQbuMn"
      },
      "source": [
        "# AWESOME: Aligning Word Embedding Spaces of Multilingual Encoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ipxcuO9vDgZ"
      },
      "source": [
        "[``awesome-align``](https://github.com/neulab/awesome-align) is a tool that can extract word alignments from multilingual BERT (mBERT) and allows you to fine-tune mBERT on parallel corpora for better alignment quality (see [our paper](https://arxiv.org/abs/2101.08231) for more details).\n",
        "\n",
        "This is a simple demo of how `awesome-align` extracts word alignments from mBERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJpRK-1_wQsJ"
      },
      "source": [
        "First, install and import the following packages. (Note that the original `awesome-align` tool does not require the `transformers` package.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODwJ_gQ8bnqR",
        "outputId": "b5c6ab28-d7dd-4581-d690-ddf271c89ed1"
      },
      "source": [
        "!pwd\n",
        "!git clone https://github.com/graehl/awesome-align.git || (cd awesome-align && git pull)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'awesome-align'...\n",
            "remote: Enumerating objects: 424, done.\u001b[K\n",
            "remote: Counting objects: 100% (223/223), done.\u001b[K\n",
            "remote: Compressing objects: 100% (130/130), done.\u001b[K\n",
            "remote: Total 424 (delta 161), reused 112 (delta 91), pack-reused 201 (from 1)\u001b[K\n",
            "Receiving objects: 100% (424/424), 619.09 KiB | 2.53 MiB/s, done.\n",
            "Resolving deltas: 100% (250/250), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx\n",
        "!pip install onnxruntime\n",
        "!pip install -r awesome-align/requirements.txt\n",
        "import sys\n",
        "sys.path.append('/content/awesome-align')\n",
        "sys.path.append('/content')\n",
        "import torch\n",
        "import itertools\n",
        "\n",
        "!pip install transformers\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u3stwJo_7p3",
        "outputId": "47af00dd-5738-488d-88ce-2b3f755dc2ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.17.0\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.21.1\n",
            "Requirement already satisfied: tokenizers>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from -r awesome-align/requirements.txt (line 1)) (0.21.1)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from -r awesome-align/requirements.txt (line 2)) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r awesome-align/requirements.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r awesome-align/requirements.txt (line 4)) (2.0.2)\n",
            "Collecting boto3 (from -r awesome-align/requirements.txt (line 5))\n",
            "  Downloading boto3-1.38.5-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from -r awesome-align/requirements.txt (line 6)) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from -r awesome-align/requirements.txt (line 7)) (2.32.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.5.2->-r awesome-align/requirements.txt (line 1)) (0.30.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r awesome-align/requirements.txt (line 2)) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r awesome-align/requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r awesome-align/requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r awesome-align/requirements.txt (line 2)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.2.0->-r awesome-align/requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.2.0->-r awesome-align/requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.2.0->-r awesome-align/requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.2.0->-r awesome-align/requirements.txt (line 2))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.2.0->-r awesome-align/requirements.txt (line 2))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.2.0->-r awesome-align/requirements.txt (line 2))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.2.0->-r awesome-align/requirements.txt (line 2))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.2.0->-r awesome-align/requirements.txt (line 2))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.2.0->-r awesome-align/requirements.txt (line 2))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r awesome-align/requirements.txt (line 2)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r awesome-align/requirements.txt (line 2)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r awesome-align/requirements.txt (line 2)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.2.0->-r awesome-align/requirements.txt (line 2))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r awesome-align/requirements.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->-r awesome-align/requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.2.0->-r awesome-align/requirements.txt (line 2)) (1.3.0)\n",
            "Collecting botocore<1.39.0,>=1.38.5 (from boto3->-r awesome-align/requirements.txt (line 5))\n",
            "  Downloading botocore-1.38.5-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->-r awesome-align/requirements.txt (line 5))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.13.0,>=0.12.0 (from boto3->-r awesome-align/requirements.txt (line 5))\n",
            "  Downloading s3transfer-0.12.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->-r awesome-align/requirements.txt (line 7)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->-r awesome-align/requirements.txt (line 7)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->-r awesome-align/requirements.txt (line 7)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->-r awesome-align/requirements.txt (line 7)) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.39.0,>=1.38.5->boto3->-r awesome-align/requirements.txt (line 5)) (2.9.0.post0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.5.2->-r awesome-align/requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.5.2->-r awesome-align/requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.2.0->-r awesome-align/requirements.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.39.0,>=1.38.5->boto3->-r awesome-align/requirements.txt (line 5)) (1.17.0)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.38.5-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.38.5-py3-none-any.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.12.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, s3transfer, nvidia-cusolver-cu12, boto3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed boto3-1.38.5 botocore-1.38.5 jmespath-1.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 s3transfer-0.12.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing\n",
        "class color:\n",
        "   PURPLE = '\\033[95m'\n",
        "   CYAN = '\\033[96m'\n",
        "   DARKCYAN = '\\033[36m'\n",
        "   BLUE = '\\033[94m'\n",
        "   GREEN = '\\033[92m'\n",
        "   YELLOW = '\\033[93m'\n",
        "   RED = '\\033[91m'\n",
        "   BOLD = '\\033[1m'\n",
        "   UNDERLINE = '\\033[4m'\n",
        "   END = '\\033[0m'\n",
        "\n",
        "def print_align(align_words, desc=''):\n",
        "    print(f\"{desc} {len(align_words)} links {align_words} for '{src}' to '{tgt}'\")\n",
        "    for x in align_words:\n",
        "      i, j = x\n",
        "      print(f'{color.BOLD}{color.BLUE}{sent_src[i]}{color.END}==={color.BOLD}{color.RED}{sent_tgt[j]}{color.END}')"
      ],
      "metadata": {
        "id": "Jr4ySKRtWotU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRvfawCbw2i7"
      },
      "source": [
        "Load the multilingual BERT model and its tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aPvLqT7eiry",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "c7bb3938fb3c4b1ba8644281707b949e",
            "b08434187a1e40cb9d0d1bc3c741eb8f",
            "bfafb1da053444898ca8c9043a282c65",
            "6d63e6ecdb024023a5f51f269a64da4a",
            "1437c350de72407ea76bc7bfd61f3e90",
            "53b9bc01c1b449bb8720b376c886bfff",
            "e907e85bbc084d53bc66e7bb985702b9",
            "7e824fdbccd6494e9d367db8817324ac",
            "af4838cd53a24c2390d2fd5389dd3a0e",
            "25b3f55ce941496b9f743e82572bc593",
            "0f0c48d26444490fb86d0bb526d6195b",
            "02abfcba05ec4c94b9be0e0b5bf95b95",
            "27fc060b99a246398dbd0178a8d2bf1f",
            "b5760e6d9a70497781b272dc6acf775e",
            "84bd4564ac304147be7f455c7a42708f",
            "56be3e22669b465596b8c638899d1673",
            "387c549af19b4903bad9d45156d9ce4e",
            "594a312a75e44b609134f53a89c73bca",
            "39cf1202822049718fd10f9b22e4c1ca",
            "388e3617b2fe4784bddb23217d985db4",
            "92ef1ef592c14c9a93814fa501fac4cb",
            "5d0f8abf22e647aea935ab5a53789869",
            "7f581f4aba2345e3b969d117cfb642bf",
            "9a4653d010d1476fb18da6017b8cdc4b",
            "dfad1e1b35a649d0a7dc11f95a05d2a9",
            "76aae583d0c9411dbcd893505683e268",
            "1bb6e20b43034864bd829d1393b6a961",
            "19d90e36cd1544f288eaf211199b3976",
            "dc17299e2d2d44598ed2e97d65cba45a",
            "4ff8fe2dd1da46178628bd084d10a89f",
            "f8ce2ac810d44b2c8c80058a412719d2",
            "f29de119e05641feb091134eb6fb2a82",
            "b06e9f9e74b74758a4f4939a0b661f8c"
          ]
        },
        "outputId": "23f4be84-a3d8-4f03-e382-032a7af7e620"
      },
      "source": [
        "model_name_or_path='bert-base-multilingual-cased'\n",
        "model_name = model_name_or_path.split('/')[-1]\n",
        "\n",
        "import transformers\n",
        "import awesome_align\n",
        "from awesome_align import modeling\n",
        "from awesome_align.configuration_bert import BertConfig\n",
        "from awesome_align.modeling import BertForMaskedLM\n",
        "from awesome_align.tokenization_bert import BertTokenizer\n",
        "from awesome_align.tokenization_utils import PreTrainedTokenizer\n",
        "from awesome_align.modeling_utils import PreTrainedModel\n",
        "\n",
        "def init_model_and_tokenizer(\n",
        "    model_name_or_path,\n",
        "    config_name = None,\n",
        "    cache_dir = None,\n",
        "    tokenizer_name = None,\n",
        "):\n",
        "  config_class, model_class, tokenizer_class = BertConfig, BertForMaskedLM, BertTokenizer\n",
        "  if config_name:\n",
        "      config = config_class.from_pretrained(config_name, cache_dir=cache_dir)\n",
        "  elif model_name_or_path:\n",
        "      config = config_class.from_pretrained(model_name_or_path, cache_dir=cache_dir)\n",
        "  else:\n",
        "      config = config_class()\n",
        "\n",
        "  if tokenizer_name:\n",
        "      tokenizer = tokenizer_class.from_pretrained(tokenizer_name, cache_dir=cache_dir)\n",
        "  elif model_name_or_path:\n",
        "      tokenizer = tokenizer_class.from_pretrained(model_name_or_path, cache_dir=cache_dir)\n",
        "  else:\n",
        "      raise ValueError(\n",
        "          \"You are instantiating a new {} tokenizer. This is not supported, but you can do it from another script, save it,\"\n",
        "          \"and load it from here, using --tokenizer_name\".format(tokenizer_class.__name__)\n",
        "      )\n",
        "\n",
        "  # pad is actually always 0\n",
        "  modeling.PAD_ID = tokenizer.pad_token_id\n",
        "  modeling.CLS_ID = tokenizer.cls_token_id\n",
        "  modeling.SEP_ID = tokenizer.sep_token_id\n",
        "\n",
        "  if model_name_or_path:\n",
        "      model = model_class.from_pretrained(\n",
        "          model_name_or_path,\n",
        "          from_tf=bool(\".ckpt\" in model_name_or_path),\n",
        "          config=config,\n",
        "          cache_dir=cache_dir,\n",
        "      )\n",
        "  else:\n",
        "      model = model_class(config=config)\n",
        "\n",
        "  return model, tokenizer\n",
        "\n",
        "USE_AWESOME_ALIGN = True\n",
        "# True caused, in export to onnx, `Boolean value of Tensor with more than one value is ambiguous`, but we fixed with ExportNthLayer wrapper\n",
        "if USE_AWESOME_ALIGN:\n",
        "  model, tokenizer = init_model_and_tokenizer(model_name_or_path)\n",
        "else:\n",
        "  model, tokenizer = transformers.AutoModel.from_pretrained(model_name_or_path), transformers.AutoTokenizer.from_pretrained(model_name_or_path)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7bb3938fb3c4b1ba8644281707b949e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02abfcba05ec4c94b9be0e0b5bf95b95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f581f4aba2345e3b969d117cfb642bf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RPxlavmxNmj"
      },
      "source": [
        "Input *tokenized* source and target sentences."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import onnx\n",
        "model.eval()\n",
        "# just sets mode of model, probably doesn't need to be under no_grad\n",
        "\n",
        "def extend_mask(attention_mask, dtype=torch.float32):\n",
        "    if attention_mask.dim() == 3:\n",
        "        extended_attention_mask = attention_mask[:, None, :, :]\n",
        "    elif attention_mask.dim() == 2:\n",
        "        extended_attention_mask = attention_mask[:, None, None, :]\n",
        "    else:\n",
        "        raise ValueError(\n",
        "             \"Wrong shape for input_ids or attention_mask\"\n",
        "        )\n",
        "    extended_attention_mask = extended_attention_mask.to(dtype=dtype)\n",
        "    extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "    return extended_attention_mask\n",
        "\n",
        "def guess_dtype(model):\n",
        "  if hasattr(model, 'get_parameter_dtype'):\n",
        "    return model.get_parameter_dtype()\n",
        "  elif hasattr(model, 'parameters'):\n",
        "    return next(model.parameters()).dtype\n",
        "  else:\n",
        "    return torch.float32\n",
        "\n",
        "def make_ones_mask(ids):\n",
        "  shape = ids.size()\n",
        "  device = ids.device\n",
        "  attention_mask = torch.ones(shape, device=device)\n",
        "  attention_mask[ids==0] = 0\n",
        "  return attention_mask\n",
        "\n",
        "def make_extended_mask(ids, dtype=torch.float32):\n",
        "  attention_mask = make_ones_mask(ids)\n",
        "  return extend_mask(attention_mask, dtype)\n",
        "\n",
        "class ExportNthLayer(torch.nn.Module):\n",
        "    def __init__(self, base_model, align_layer_max=8):\n",
        "        super().__init__()\n",
        "        e = base_model.bert if hasattr(base_model, 'bert') else base_model\n",
        "        self.bert = e\n",
        "        self.embeddings = e.embeddings\n",
        "        # For BERT, num_hidden_layers is in config\n",
        "        self.config = e.config\n",
        "        self.num_layers = min(e.config.num_hidden_layers, align_layer_max)\n",
        "        e = e.encoder if hasattr(e, 'encoder') else e\n",
        "        self.encoder = e\n",
        "        self.layer = e.layer[:self.num_layers]\n",
        "        print(f'{self.layer}')\n",
        "\n",
        "    def forward(self, ids, attention_mask=None, position_ids=None):\n",
        "      shape = ids.size()\n",
        "      device = ids.device\n",
        "      if attention_mask is None:\n",
        "        attention_mask = make_ones_mask(ids)\n",
        "\n",
        "      # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
        "      # ourselves in which case we just need to make it broadcastable to all heads.\n",
        "      extended_attention_mask = extend_mask(attention_mask, guess_dtype(self.bert))\n",
        "      input_shape = ids.size()\n",
        "      token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "      hidden_states = self.embeddings(ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
        "\n",
        "      if self.layer is not None:\n",
        "        for i, layer in enumerate(self.layer):\n",
        "          hidden_states = layer(hidden_states, attention_mask=extended_attention_mask)\n",
        "        return hidden_states\n",
        "      else:\n",
        "        return self.bert(ids, attention_mask)\n",
        "\n",
        "USE_ONNX_OPSET=18 #12-13 fails checker (shape missing). 14 passes checker. 16 has improved bert perf. 18 has best (ok for onnxruntime 1.15 which we use on linux)\n",
        "def to_onnx(model, onnx_file_path, inputs=['input_ids', 'attention_mask'], outputs=['output'], dynamic=True, batch=True, align_layer=None, opset_version=USE_ONNX_OPSET, return_tensor_names=True):\n",
        "  captions = {0 : 'batch_size', 1: 'sequence_length'} if batch else {0 : 'sequence_length'}\n",
        "  dynamic_axes = {}\n",
        "  if dynamic:\n",
        "    for k in inputs:\n",
        "      dynamic_axes[k] = captions\n",
        "    for k in outputs:\n",
        "      dynamic_axes[k] = captions\n",
        "\n",
        "  # Create dummy input data\n",
        "  batch_size = 1\n",
        "  sequence_length = 128\n",
        "  dims = (batch_size, sequence_length) if batch else (sequence_length,)\n",
        "  inputs_ones = tuple(torch.ones(dims) if x != 'input_ids' else torch.randint(0, model.config.vocab_size, dims) for x in inputs)\n",
        "\n",
        "  hasbert = hasattr(model, 'bert')\n",
        "  #print(f'hasbert={hasbert}')\n",
        "  model = model.bert if hasbert else model\n",
        "  # TODO: figure out how to do first nth encoder layers for non-awesome-align bert\n",
        "  model = ExportNthLayer(model, align_layer) if USE_AWESOME_ALIGN and align_layer is not None else model\n",
        "  # Export the model to ONNX\n",
        "  torch.onnx.export(\n",
        "      model,\n",
        "      inputs_ones, #(input_ids, attention_mask),\n",
        "      onnx_file_path,\n",
        "      export_params=True,\n",
        "      opset_version=opset_version,\n",
        "      do_constant_folding=True,\n",
        "      input_names = inputs,\n",
        "      output_names = outputs,\n",
        "      dynamic_axes=dynamic_axes,\n",
        "  )\n",
        "\n",
        "  if return_tensor_names:\n",
        "    om = onnx.load(onnx_file_path)\n",
        "\n",
        "    print('initializers: ...')\n",
        "    for node in om.graph.initializer[-19:]:\n",
        "      print(f'{node.name}')\n",
        "    return list(x.output for x in om.graph.node)\n",
        "  else:\n",
        "    return f\"Model exported to {onnx_file_path}\"\n",
        "\n",
        "\n",
        "DO_ONNX_EXPORT=True\n",
        "\n",
        "def onnxpathm(x):\n",
        "  return f'{model_name}-nlayer{x}.onnx'\n",
        "align_layer_max=10\n",
        "onnxpath=onnxpathm(align_layer_max)\n",
        "if DO_ONNX_EXPORT:\n",
        "    #onnxruntime.python.tools.transformers.export_onnx_model_from_pt(...)\n",
        "  if False and USE_AWESOME_ALIGN:\n",
        "    !CUDA_VISIBLE_DEVICES=0 PYTHONPATH=/content/awesome-align python /content/awesome-align/run_align.py --model_name_or_path=bert-base-multilingual-cased --output_onnx=$onnxpath --max_layer=$align_layer_max\n",
        "  else:\n",
        "    names = to_onnx(model, onnxpath, align_layer=align_layer_max)\n",
        "    print(f'... ({len(names)})')\n",
        "    for x in names[-199:]: print(str(x))\n",
        "  !du -h $onnxpath\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mUNmubaq4UQ",
        "outputId": "3a8a32ef-8368-430b-8023-e046aed95616"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ModuleList(\n",
            "  (0-9): 10 x BertLayer(\n",
            "    (attention): BertAttention(\n",
            "      (self): BertSelfAttention(\n",
            "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (output): BertSelfOutput(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (intermediate): BertIntermediate(\n",
            "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "    )\n",
            "    (output): BertOutput(\n",
            "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "initializers: ...\n",
            "onnx::MatMul_1359\n",
            "onnx::MatMul_1360\n",
            "onnx::MatMul_1361\n",
            "onnx::MatMul_1362\n",
            "onnx::MatMul_1370\n",
            "onnx::MatMul_1371\n",
            "onnx::MatMul_1372\n",
            "onnx::MatMul_1373\n",
            "onnx::MatMul_1374\n",
            "onnx::MatMul_1375\n",
            "onnx::MatMul_1383\n",
            "onnx::MatMul_1384\n",
            "onnx::MatMul_1385\n",
            "onnx::MatMul_1386\n",
            "onnx::MatMul_1387\n",
            "onnx::MatMul_1388\n",
            "onnx::MatMul_1396\n",
            "onnx::MatMul_1397\n",
            "onnx::MatMul_1398\n",
            "... (937)\n",
            "['/layer.7/attention/self/Constant_15_output_0']\n",
            "['/layer.7/attention/self/Concat_3_output_0']\n",
            "['/layer.7/attention/self/Reshape_3_output_0']\n",
            "['/layer.7/attention/output/dense/MatMul_output_0']\n",
            "['/layer.7/attention/output/dense/Add_output_0']\n",
            "['/layer.7/attention/output/Add_output_0']\n",
            "['/layer.7/attention/output/LayerNorm/LayerNormalization_output_0']\n",
            "['/layer.7/intermediate/dense/MatMul_output_0']\n",
            "['/layer.7/intermediate/dense/Add_output_0']\n",
            "['/layer.7/intermediate/Constant_output_0']\n",
            "['/layer.7/intermediate/Div_output_0']\n",
            "['/layer.7/intermediate/Erf_output_0']\n",
            "['/layer.7/intermediate/Constant_1_output_0']\n",
            "['/layer.7/intermediate/Add_output_0']\n",
            "['/layer.7/intermediate/Mul_output_0']\n",
            "['/layer.7/intermediate/Constant_2_output_0']\n",
            "['/layer.7/intermediate/Mul_1_output_0']\n",
            "['/layer.7/output/dense/MatMul_output_0']\n",
            "['/layer.7/output/dense/Add_output_0']\n",
            "['/layer.7/output/Add_output_0']\n",
            "['/layer.7/output/LayerNorm/LayerNormalization_output_0']\n",
            "['/layer.8/attention/self/query/MatMul_output_0']\n",
            "['/layer.8/attention/self/query/Add_output_0']\n",
            "['/layer.8/attention/self/key/MatMul_output_0']\n",
            "['/layer.8/attention/self/key/Add_output_0']\n",
            "['/layer.8/attention/self/value/MatMul_output_0']\n",
            "['/layer.8/attention/self/value/Add_output_0']\n",
            "['/layer.8/attention/self/Shape_output_0']\n",
            "['/layer.8/attention/self/Constant_output_0']\n",
            "['/layer.8/attention/self/Gather_output_0']\n",
            "['/layer.8/attention/self/Shape_1_output_0']\n",
            "['/layer.8/attention/self/Constant_1_output_0']\n",
            "['/layer.8/attention/self/Gather_1_output_0']\n",
            "['onnx::Unsqueeze_1080']\n",
            "['/layer.8/attention/self/Unsqueeze_output_0']\n",
            "['onnx::Unsqueeze_1082']\n",
            "['/layer.8/attention/self/Unsqueeze_1_output_0']\n",
            "['/layer.8/attention/self/Constant_2_output_0']\n",
            "['/layer.8/attention/self/Constant_3_output_0']\n",
            "['/layer.8/attention/self/Concat_output_0']\n",
            "['/layer.8/attention/self/Reshape_output_0']\n",
            "['/layer.8/attention/self/Transpose_output_0']\n",
            "['/layer.8/attention/self/Shape_2_output_0']\n",
            "['/layer.8/attention/self/Constant_4_output_0']\n",
            "['/layer.8/attention/self/Gather_2_output_0']\n",
            "['/layer.8/attention/self/Shape_3_output_0']\n",
            "['/layer.8/attention/self/Constant_5_output_0']\n",
            "['/layer.8/attention/self/Gather_3_output_0']\n",
            "['onnx::Unsqueeze_1097']\n",
            "['/layer.8/attention/self/Unsqueeze_2_output_0']\n",
            "['onnx::Unsqueeze_1099']\n",
            "['/layer.8/attention/self/Unsqueeze_3_output_0']\n",
            "['/layer.8/attention/self/Constant_6_output_0']\n",
            "['/layer.8/attention/self/Constant_7_output_0']\n",
            "['/layer.8/attention/self/Concat_1_output_0']\n",
            "['/layer.8/attention/self/Reshape_1_output_0']\n",
            "['/layer.8/attention/self/Shape_4_output_0']\n",
            "['/layer.8/attention/self/Constant_8_output_0']\n",
            "['/layer.8/attention/self/Gather_4_output_0']\n",
            "['/layer.8/attention/self/Shape_5_output_0']\n",
            "['/layer.8/attention/self/Constant_9_output_0']\n",
            "['/layer.8/attention/self/Gather_5_output_0']\n",
            "['onnx::Unsqueeze_1113']\n",
            "['/layer.8/attention/self/Unsqueeze_4_output_0']\n",
            "['onnx::Unsqueeze_1115']\n",
            "['/layer.8/attention/self/Unsqueeze_5_output_0']\n",
            "['/layer.8/attention/self/Constant_10_output_0']\n",
            "['/layer.8/attention/self/Constant_11_output_0']\n",
            "['/layer.8/attention/self/Concat_2_output_0']\n",
            "['/layer.8/attention/self/Reshape_2_output_0']\n",
            "['/layer.8/attention/self/Transpose_1_output_0']\n",
            "['/layer.8/attention/self/Transpose_2_output_0']\n",
            "['/layer.8/attention/self/MatMul_output_0']\n",
            "['/layer.8/attention/self/Constant_12_output_0']\n",
            "['/layer.8/attention/self/Div_output_0']\n",
            "['/layer.8/attention/self/Add_output_0']\n",
            "['/layer.8/attention/self/Softmax_output_0']\n",
            "['/layer.8/attention/self/MatMul_1_output_0']\n",
            "['/layer.8/attention/self/Transpose_3_output_0']\n",
            "['/layer.8/attention/self/Shape_6_output_0']\n",
            "['/layer.8/attention/self/Constant_13_output_0']\n",
            "['/layer.8/attention/self/Gather_6_output_0']\n",
            "['/layer.8/attention/self/Shape_7_output_0']\n",
            "['/layer.8/attention/self/Constant_14_output_0']\n",
            "['/layer.8/attention/self/Gather_7_output_0']\n",
            "['onnx::Unsqueeze_1138']\n",
            "['/layer.8/attention/self/Unsqueeze_6_output_0']\n",
            "['onnx::Unsqueeze_1140']\n",
            "['/layer.8/attention/self/Unsqueeze_7_output_0']\n",
            "['/layer.8/attention/self/Constant_15_output_0']\n",
            "['/layer.8/attention/self/Concat_3_output_0']\n",
            "['/layer.8/attention/self/Reshape_3_output_0']\n",
            "['/layer.8/attention/output/dense/MatMul_output_0']\n",
            "['/layer.8/attention/output/dense/Add_output_0']\n",
            "['/layer.8/attention/output/Add_output_0']\n",
            "['/layer.8/attention/output/LayerNorm/LayerNormalization_output_0']\n",
            "['/layer.8/intermediate/dense/MatMul_output_0']\n",
            "['/layer.8/intermediate/dense/Add_output_0']\n",
            "['/layer.8/intermediate/Constant_output_0']\n",
            "['/layer.8/intermediate/Div_output_0']\n",
            "['/layer.8/intermediate/Erf_output_0']\n",
            "['/layer.8/intermediate/Constant_1_output_0']\n",
            "['/layer.8/intermediate/Add_output_0']\n",
            "['/layer.8/intermediate/Mul_output_0']\n",
            "['/layer.8/intermediate/Constant_2_output_0']\n",
            "['/layer.8/intermediate/Mul_1_output_0']\n",
            "['/layer.8/output/dense/MatMul_output_0']\n",
            "['/layer.8/output/dense/Add_output_0']\n",
            "['/layer.8/output/Add_output_0']\n",
            "['/layer.8/output/LayerNorm/LayerNormalization_output_0']\n",
            "['/layer.9/attention/self/query/MatMul_output_0']\n",
            "['/layer.9/attention/self/query/Add_output_0']\n",
            "['/layer.9/attention/self/key/MatMul_output_0']\n",
            "['/layer.9/attention/self/key/Add_output_0']\n",
            "['/layer.9/attention/self/value/MatMul_output_0']\n",
            "['/layer.9/attention/self/value/Add_output_0']\n",
            "['/layer.9/attention/self/Shape_output_0']\n",
            "['/layer.9/attention/self/Constant_output_0']\n",
            "['/layer.9/attention/self/Gather_output_0']\n",
            "['/layer.9/attention/self/Shape_1_output_0']\n",
            "['/layer.9/attention/self/Constant_1_output_0']\n",
            "['/layer.9/attention/self/Gather_1_output_0']\n",
            "['onnx::Unsqueeze_1182']\n",
            "['/layer.9/attention/self/Unsqueeze_output_0']\n",
            "['onnx::Unsqueeze_1184']\n",
            "['/layer.9/attention/self/Unsqueeze_1_output_0']\n",
            "['/layer.9/attention/self/Constant_2_output_0']\n",
            "['/layer.9/attention/self/Constant_3_output_0']\n",
            "['/layer.9/attention/self/Concat_output_0']\n",
            "['/layer.9/attention/self/Reshape_output_0']\n",
            "['/layer.9/attention/self/Transpose_output_0']\n",
            "['/layer.9/attention/self/Shape_2_output_0']\n",
            "['/layer.9/attention/self/Constant_4_output_0']\n",
            "['/layer.9/attention/self/Gather_2_output_0']\n",
            "['/layer.9/attention/self/Shape_3_output_0']\n",
            "['/layer.9/attention/self/Constant_5_output_0']\n",
            "['/layer.9/attention/self/Gather_3_output_0']\n",
            "['onnx::Unsqueeze_1199']\n",
            "['/layer.9/attention/self/Unsqueeze_2_output_0']\n",
            "['onnx::Unsqueeze_1201']\n",
            "['/layer.9/attention/self/Unsqueeze_3_output_0']\n",
            "['/layer.9/attention/self/Constant_6_output_0']\n",
            "['/layer.9/attention/self/Constant_7_output_0']\n",
            "['/layer.9/attention/self/Concat_1_output_0']\n",
            "['/layer.9/attention/self/Reshape_1_output_0']\n",
            "['/layer.9/attention/self/Shape_4_output_0']\n",
            "['/layer.9/attention/self/Constant_8_output_0']\n",
            "['/layer.9/attention/self/Gather_4_output_0']\n",
            "['/layer.9/attention/self/Shape_5_output_0']\n",
            "['/layer.9/attention/self/Constant_9_output_0']\n",
            "['/layer.9/attention/self/Gather_5_output_0']\n",
            "['onnx::Unsqueeze_1215']\n",
            "['/layer.9/attention/self/Unsqueeze_4_output_0']\n",
            "['onnx::Unsqueeze_1217']\n",
            "['/layer.9/attention/self/Unsqueeze_5_output_0']\n",
            "['/layer.9/attention/self/Constant_10_output_0']\n",
            "['/layer.9/attention/self/Constant_11_output_0']\n",
            "['/layer.9/attention/self/Concat_2_output_0']\n",
            "['/layer.9/attention/self/Reshape_2_output_0']\n",
            "['/layer.9/attention/self/Transpose_1_output_0']\n",
            "['/layer.9/attention/self/Transpose_2_output_0']\n",
            "['/layer.9/attention/self/MatMul_output_0']\n",
            "['/layer.9/attention/self/Constant_12_output_0']\n",
            "['/layer.9/attention/self/Div_output_0']\n",
            "['/layer.9/attention/self/Add_output_0']\n",
            "['/layer.9/attention/self/Softmax_output_0']\n",
            "['/layer.9/attention/self/MatMul_1_output_0']\n",
            "['/layer.9/attention/self/Transpose_3_output_0']\n",
            "['/layer.9/attention/self/Shape_6_output_0']\n",
            "['/layer.9/attention/self/Constant_13_output_0']\n",
            "['/layer.9/attention/self/Gather_6_output_0']\n",
            "['/layer.9/attention/self/Shape_7_output_0']\n",
            "['/layer.9/attention/self/Constant_14_output_0']\n",
            "['/layer.9/attention/self/Gather_7_output_0']\n",
            "['onnx::Unsqueeze_1240']\n",
            "['/layer.9/attention/self/Unsqueeze_6_output_0']\n",
            "['onnx::Unsqueeze_1242']\n",
            "['/layer.9/attention/self/Unsqueeze_7_output_0']\n",
            "['/layer.9/attention/self/Constant_15_output_0']\n",
            "['/layer.9/attention/self/Concat_3_output_0']\n",
            "['/layer.9/attention/self/Reshape_3_output_0']\n",
            "['/layer.9/attention/output/dense/MatMul_output_0']\n",
            "['/layer.9/attention/output/dense/Add_output_0']\n",
            "['/layer.9/attention/output/Add_output_0']\n",
            "['/layer.9/attention/output/LayerNorm/LayerNormalization_output_0']\n",
            "['/layer.9/intermediate/dense/MatMul_output_0']\n",
            "['/layer.9/intermediate/dense/Add_output_0']\n",
            "['/layer.9/intermediate/Constant_output_0']\n",
            "['/layer.9/intermediate/Div_output_0']\n",
            "['/layer.9/intermediate/Erf_output_0']\n",
            "['/layer.9/intermediate/Constant_1_output_0']\n",
            "['/layer.9/intermediate/Add_output_0']\n",
            "['/layer.9/intermediate/Mul_output_0']\n",
            "['/layer.9/intermediate/Constant_2_output_0']\n",
            "['/layer.9/intermediate/Mul_1_output_0']\n",
            "['/layer.9/output/dense/MatMul_output_0']\n",
            "['/layer.9/output/dense/Add_output_0']\n",
            "['/layer.9/output/Add_output_0']\n",
            "['output']\n",
            "623M\tbert-base-multilingual-cased-nlayer10.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COPY_TO_DRIVE=False\n",
        "def cpdrive(onnxpath):\n",
        " if COPY_TO_DRIVE:\n",
        "  from google.colab import drive\n",
        "  driveroot = '/content/gdrive'\n",
        "  drive.mount(driveroot, force_remount=True)\n",
        "  drivedir=f'{driveroot}/MyDrive'\n",
        "  subdir=f'{drivedir}/awesome'\n",
        "  !mkdir -p $subdir\n",
        "  onnxname=onnxpath.split('/')[-1]\n",
        "  onnxto=f'{subdir}/{onnxname}'\n",
        "  print(onnxto)\n",
        "  print(onnxpath)\n",
        "  !cp $onnxpath $onnxto\n",
        "  !du -h $onnxto\n",
        "cpdrive(onnxpath)"
      ],
      "metadata": {
        "id": "GfuHcEmjWUWF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfDM0w2kfHyJ"
      },
      "source": [
        "src = 'I bought a new car because I was going through a midlife crisis .'\n",
        "tgt = 'Я купил новую тачку , потому что я переживал кризис среднего возраста .'\n",
        "tgt = 'Compré un auto nuevo porque estaba pasando por una crisis de la mediana edad .'\n",
        "src = 'I love you'\n",
        "tgt = \"Je t ' aime\"\n",
        "src = 'He said : \"I love you \" .'\n",
        "tgt = \"Il a dit : « Je t ' aime » .\"\n",
        "srctgt = f'{src} ||| {tgt}'\n",
        "fpar = 'srctgt.txt'\n",
        "with open(fpar, 'w') as f:\n",
        "  f.write(srctgt)\n",
        "if False:\n",
        "  !rm align.txt\n",
        "  !CUDA_VISIBLE_DEVICES=0 PYTHONPATH=/content/awesome-align python /content/awesome-align/run_align.py --output_file=align.txt --model_name_or_path=\"$model_name_or_path\" --data_file=\"$fpar\" --extraction='softmax' --softmax_threshold=1e-3 --batch_size=32\n",
        "  !cat align.txt"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-processing\n",
        "def wstok(x): return x.strip().split()\n",
        "def subwords(xs): return [tokenizer.tokenize(x) for x in xs]\n",
        "def ids(xs): return [tokenizer.convert_tokens_to_ids(x) for x in xs]\n",
        "sent_src, sent_tgt = wstok(src), wstok(tgt)\n",
        "token_src, token_tgt = subwords(sent_src), subwords(sent_tgt)\n",
        "\n",
        "wid_src, wid_tgt = ids(token_src), ids(token_tgt)\n",
        "#def tokenizer_max_len(tokenizer): return tokenizer.max_len_single_sentence if hasattr(tokenizer, 'max_len_single_sentence') else tokenizer.model_max_length\n",
        "maxlenkw = {}\n",
        "if hasattr(tokenizer, 'model_max_length'):\n",
        "  maxlenkw['model_max_length'] = tokenizer.model_max_length\n",
        "  maxlenkw['truncation'] = True\n",
        "else:\n",
        "  maxlenkw['max_length'] = tokenizer.max_len\n",
        "\n",
        "def ids_for_model(ids, model, tokenizer): return tokenizer.prepare_for_model(list(itertools.chain(*ids)), return_tensors='pt', **maxlenkw)['input_ids']\n",
        "print(f'wid {len(wid_src)} x {len(wid_tgt)}')\n",
        "ids_src, ids_tgt = ids_for_model(wid_src, model, tokenizer), ids_for_model(wid_tgt, model, tokenizer)\n",
        "print(f'{token_src}')\n",
        "print(f'{ids_src}')\n",
        "print(f'{token_tgt}')\n",
        "print(f'{ids_tgt}')\n",
        "sub2word_map_src = []\n",
        "for i, word_list in enumerate(token_src):\n",
        "  sub2word_map_src += [i for x in word_list]\n",
        "sub2word_map_tgt = []\n",
        "for i, word_list in enumerate(token_tgt):\n",
        "  sub2word_map_tgt += [i for x in word_list]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YabaixKkldP_",
        "outputId": "8793a54e-2cb7-433f-ad9b-ba09c554aad7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wid 8 x 11\n",
            "[['He'], ['said'], [':'], ['\"', 'I'], ['love'], ['you'], ['\"'], ['.']]\n",
            "tensor([[  101, 10357, 12415,   131,   107,   146, 16138, 13028,   107,   119,\n",
            "           102]])\n",
            "[['Il'], ['a'], ['dit'], [':'], ['«'], ['Je'], ['t'], [\"'\"], ['aime'], ['»'], ['.']]\n",
            "tensor([[  101, 10282,   169, 11690,   131,   208, 13796,   188,   112, 62691,\n",
            "           220,   119,   102]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpUa-ZqUxZ8Z"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_output_layer(x, opset_version=18):\n",
        "  n = 'LayerNormalization_output_0' if opset_version >= 18 else 'Add_1_output_0'\n",
        "  return '/layer.7/output/LayerNorm/' + n\n",
        "\n",
        "layername = encoder_output_layer(7, USE_ONNX_OPSET)\n",
        "print(layername)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3FlRpS-dYFv",
        "outputId": "d393070f-523e-4662-f252-e9301297b4b5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/layer.7/output/LayerNorm/LayerNormalization_output_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import onnxruntime as ort\n",
        "import onnxruntime as rt\n",
        "\n",
        "align_layer_max = 10\n",
        "onnxpath = onnxpathm(align_layer_max)\n",
        "!ls -l $onnxpath\n",
        "\n",
        "def onnx_inputs(path, inputs=None):\n",
        "  if True or inputs is None:\n",
        "    return [x.name for x in onnx.load(path).graph.input]\n",
        "  return inputs\n",
        "\n",
        "import onnx\n",
        "\n",
        "def modify_onnx_outputs(path, onnxpathout, outputs, inputs=None, checker=True):\n",
        "  onnx.utils.extract_model(path, onnxpathout, onnx_inputs(path, inputs), outputs)\n",
        "  if checker:\n",
        "    onnx.checker.check_model(onnxpathout)\n",
        "  return onnxpathout\n",
        "\n",
        "\n",
        "def onnxmask(ids):\n",
        "  return (ids != 0).to(torch.float32)\n",
        "  #return make_extended_mask(ids)[0, 0, :, :]\n",
        "\n",
        "def onnx_word_encs(session, ids_src):\n",
        "  msrc = onnxmask(ids_src)\n",
        "  print(f'ids #ids={ids_src.size()} {ids_src}')\n",
        "  print(f'mask (# {msrc.size()}): {msrc}')\n",
        "  osrc = torch.tensor(session.run(output_names, {input_names[0]: ids_src.numpy(), input_names[1]: msrc.numpy()})[0][:,1:-1,:])\n",
        "  print(f'output #osrc={osrc.size()} {osrc}')\n",
        "  return osrc\n",
        "\n",
        "def alignpairs(out_src, out_tgt, sub2word_map_src, sub2word_map_tgt, threshold, debug=False):\n",
        "      dot_prod = torch.matmul(out_src, out_tgt.transpose(-1, -2))\n",
        "      print(f'#prod={dot_prod.size()} {dot_prod}')\n",
        "      softmax_srctgt = torch.nn.Softmax(dim=-1)(dot_prod)\n",
        "      softmax_tgtsrc = torch.nn.Softmax(dim=-2)(dot_prod)\n",
        "\n",
        "      # tryalso entmax15(dot_prod, dim=...)? also TODO: before softmax mask off cls sep pad tokens\n",
        "      srctgt = softmax_srctgt > threshold\n",
        "      tgtsrc = softmax_tgtsrc > threshold\n",
        "      softmax_inter = srctgt * tgtsrc\n",
        "      if debug:\n",
        "        print(f'> {threshold}:\\n {srctgt}\\n {tgtsrc}\\n {softmax_inter}')\n",
        "\n",
        "      align_subwords = torch.nonzero(softmax_inter, as_tuple=False)\n",
        "      align_words = set()\n",
        "      for xyz in align_subwords:\n",
        "        i, j = xyz[-2], xyz[-1]\n",
        "        #print(f'subword: {i}-{j}')\n",
        "        align_words.add( (sub2word_map_src[i], sub2word_map_tgt[j]) )\n",
        "      return sorted(list(align_words))\n",
        "\n",
        "sess_options = rt.SessionOptions()\n",
        "sess_options.graph_optimization_level = rt.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
        "\n",
        "#'output',\n",
        "for use_output in [layername]:\n",
        "  print(use_output)\n",
        "\n",
        "  session_path = onnxpath\n",
        "  if use_output is not None and use_output != 'output':\n",
        "    onnxpathout = f'{onnxpath}.out.{use_output.replace(\"/\",\"_\")}'\n",
        "    assert onnxpathout != onnxpath\n",
        "    print(onnxpathout)\n",
        "    session_path = modify_onnx_outputs(onnxpath, onnxpathout, outputs=[use_output], inputs=['input_ids', 'attention_mask'], checker=USE_ONNX_OPSET>13)\n",
        "    cpdrive(onnxpathout)\n",
        "\n",
        "  !du -h $session_path\n",
        "  session = ort.InferenceSession(session_path, sess_options=sess_options, providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
        "\n",
        "  input_names = [x.name for x in session.get_inputs()]\n",
        "  output_names = [x.name for x in session.get_outputs()]\n",
        "  print(input_names)\n",
        "  print(output_names)\n",
        "\n",
        "  osrc = onnx_word_encs(session, ids_src)\n",
        "  otgt = onnx_word_encs(session, ids_tgt)\n",
        "  del session\n",
        "  print(f'{osrc.size()} x {otgt.size()}')\n",
        "\n",
        "  # , 1e-8\n",
        "  for threshold in [1e-3]:\n",
        "    align_words = alignpairs(osrc, otgt, sub2word_map_src, sub2word_map_tgt, threshold, debug=True)\n",
        "    # 13-14 2-1 10-8 0-0 5-4 4-2 12-9 11-12 3-3 8-6 1-0 7-5 9-7\n",
        "    # [(0, 0), (1, 0), (2, 1), (3, 3), (4, 2), (5, 4), (7, 5), (8, 6), (9, 7), (10, 8), (12, 9), (13, 14)]\n",
        "    print_align(align_words, f'onnx {use_output} {threshold}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO3h_lzzecUj",
        "outputId": "1e45ffd0-426b-4b3f-b694-e636bf083f2a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 652498330 Apr 30 17:11 bert-base-multilingual-cased-nlayer10.onnx\n",
            "/layer.7/output/LayerNorm/LayerNormalization_output_0\n",
            "bert-base-multilingual-cased-nlayer10.onnx.out._layer.7_output_LayerNorm_LayerNormalization_output_0\n",
            "569M\tbert-base-multilingual-cased-nlayer10.onnx.out._layer.7_output_LayerNorm_LayerNormalization_output_0\n",
            "['input_ids', 'attention_mask']\n",
            "['/layer.7/output/LayerNorm/LayerNormalization_output_0']\n",
            "ids #ids=torch.Size([1, 11]) tensor([[  101, 10357, 12415,   131,   107,   146, 16138, 13028,   107,   119,\n",
            "           102]])\n",
            "mask (# torch.Size([1, 11])): tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
            "output #osrc=torch.Size([1, 9, 768]) tensor([[[-0.1832,  0.2301, -0.1035,  ...,  0.6807,  0.6071, -1.6575],\n",
            "         [ 0.4323,  0.1902, -1.6653,  ...,  0.1778,  0.8358, -1.7789],\n",
            "         [ 0.4596, -0.2088, -0.5047,  ...,  1.0152,  0.2869, -1.8302],\n",
            "         ...,\n",
            "         [ 0.5373,  0.2568, -0.1486,  ...,  2.3190, -0.2211, -0.6562],\n",
            "         [ 0.1683,  0.6517, -0.1694,  ...,  1.2705,  0.7140, -1.3385],\n",
            "         [-0.2063, -0.7791, -1.3159,  ..., -0.1008,  0.1639, -1.1409]]])\n",
            "ids #ids=torch.Size([1, 13]) tensor([[  101, 10282,   169, 11690,   131,   208, 13796,   188,   112, 62691,\n",
            "           220,   119,   102]])\n",
            "mask (# torch.Size([1, 13])): tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
            "output #osrc=torch.Size([1, 11, 768]) tensor([[[ 0.2093,  0.1040, -0.1285,  ...,  0.4456,  0.1834, -1.2994],\n",
            "         [ 0.8386,  0.2411, -0.5434,  ..., -0.7240,  0.4424, -1.2849],\n",
            "         [ 0.3410,  0.0415, -1.1877,  ...,  0.1197,  0.7296, -1.5853],\n",
            "         ...,\n",
            "         [ 0.3190,  0.8175, -0.7412,  ...,  1.0361,  0.1521,  0.4982],\n",
            "         [-0.0069,  0.5204, -0.6243,  ...,  0.6005,  0.8606, -0.3178],\n",
            "         [-0.0997, -0.5127, -1.0574,  ..., -0.3257,  0.1768, -0.5110]]])\n",
            "torch.Size([1, 9, 768]) x torch.Size([1, 11, 768])\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[480.7970, 388.8700, 373.6476, 322.1278, 308.2495, 317.7530, 273.1320,\n",
            "          243.3498, 299.0754, 314.3121, 337.3238],\n",
            "         [363.9534, 404.1547, 507.5453, 399.1205, 327.3409, 288.5063, 280.5952,\n",
            "          242.8659, 317.4865, 328.7916, 320.4957],\n",
            "         [316.3683, 322.2918, 407.1098, 557.4952, 431.5146, 317.3144, 305.5077,\n",
            "          270.8038, 310.0857, 347.6599, 321.4491],\n",
            "         [307.0907, 286.1565, 339.3594, 409.0097, 552.6923, 390.9414, 343.1424,\n",
            "          312.1388, 326.9194, 366.6590, 306.3810],\n",
            "         [318.1642, 310.7201, 283.7672, 296.6276, 364.4221, 506.0782, 420.4072,\n",
            "          386.6420, 383.8266, 324.9623, 244.8477],\n",
            "         [240.5326, 284.1683, 312.5776, 265.6249, 320.0528, 379.2168, 411.1400,\n",
            "          343.4152, 458.6316, 309.7630, 221.5098],\n",
            "         [297.2114, 266.7160, 310.9753, 306.2937, 318.5081, 389.6705, 386.7861,\n",
            "          334.4803, 458.9668, 360.1595, 255.9838],\n",
            "         [288.2963, 285.9329, 315.7629, 333.7751, 363.2664, 325.2296, 345.8814,\n",
            "          303.1625, 371.8897, 531.4419, 315.7959],\n",
            "         [315.0843, 289.0130, 300.0241, 317.6150, 305.2802, 260.8406, 248.2436,\n",
            "          214.6257, 270.2801, 327.9850, 545.2692]]])\n",
            "onnx /layer.7/output/LayerNorm/LayerNormalization_output_0 0.001 9 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (4, 8), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94mlove\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:118: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# alignment\n",
        "\n",
        "def sents_without_startend(batch): return batch[:, 1:-1]\n",
        "if USE_AWESOME_ALIGN:\n",
        "  def hiddens(model, ids, align_layer):\n",
        "    return sents_without_startend(model.bert(ids, align_layer=align_layer, attention_mask=(ids!=0)))\n",
        "else:\n",
        "  def hidden(model, ids): return model(ids.unsqueeze(0), output_hidden_states=True)[2]\n",
        "  def hiddens(model, ids, align_layer):\n",
        "    return sents_without_startend(hidden(model, ids)[align_layer])\n",
        "\n",
        "\n",
        "DECODE_AWESOME_ALIGN=False\n",
        "print(f'USE_AWESOME_ALIGN={USE_AWESOME_ALIGN} decode:{DECODE_AWESOME_ALIGN}')\n",
        "for align_layer in range(max(0,align_layer_max - 3),align_layer_max+1):\n",
        " last_align = None\n",
        " threshold = 1e-3\n",
        " for it in range(6):\n",
        "   for repeat in range(2):\n",
        "    if DECODE_AWESOME_ALIGN and USE_AWESOME_ALIGN:\n",
        "      # get_aligned_word takes a batch.\n",
        "      # print(f'{len(ids_src[0])} x {len(ids_tgt[0])}')\n",
        "      align_words = model.get_aligned_word(ids_src, ids_tgt, (sub2word_map_src,), (sub2word_map_tgt,), 'cpu', len(ids_src), len(ids_tgt), align_layer, 'softmax', threshold, True)[0]\n",
        "    else:\n",
        "      with torch.no_grad():\n",
        "        out_src = hiddens(model, ids_src, align_layer)\n",
        "        out_tgt = hiddens(model, ids_tgt, align_layer)\n",
        "        #pdb.set_trace()\n",
        "        #out_src = model(ids_src.unsqueeze(0), output_hidden_states=True)[2][align_layer][0, 1:-1]\n",
        "        #out_tgt = model(ids_tgt.unsqueeze(0), output_hidden_states=True)[2][align_layer][0, 1:-1]\n",
        "        align_words = alignpairs(out_src, out_tgt, sub2word_map_src, sub2word_map_tgt, threshold)\n",
        "\n",
        "    align_words = sorted(list(align_words))\n",
        "    if align_words != last_align:\n",
        "      print_align(align_words,desc = f' (layer {align_layer} > {threshold:.3g})')\n",
        "    print(\".\\n\")\n",
        "\n",
        "    last_align = align_words\n",
        "    threshold = threshold * 1e-1"
      ],
      "metadata": {
        "id": "wn-h-WHTl2fm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cbcfa43-e415-464d-cec2-c21f532d4846"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE_AWESOME_ALIGN=True decode:False\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[479.6965, 376.8166, 337.2014, 321.8773, 309.0537, 334.1031, 278.5484,\n",
            "          249.6545, 316.6157, 316.4303, 333.0290],\n",
            "         [310.7386, 351.1358, 411.0678, 346.1087, 312.3040, 254.1986, 263.6411,\n",
            "          237.0275, 301.7308, 302.8228, 290.1710],\n",
            "         [299.4064, 305.0386, 371.4490, 523.4986, 399.0038, 277.5424, 286.3756,\n",
            "          258.1493, 305.3272, 307.0056, 308.5514],\n",
            "         [293.7929, 269.5833, 306.9624, 387.2483, 513.0092, 370.0731, 319.9579,\n",
            "          289.8665, 322.8041, 341.1240, 300.2899],\n",
            "         [333.0021, 293.0295, 253.4147, 278.2157, 347.4464, 481.9901, 410.2361,\n",
            "          354.5654, 379.8192, 309.5771, 261.1153],\n",
            "         [238.4029, 263.6733, 277.3986, 258.7135, 301.6373, 365.7518, 406.9039,\n",
            "          355.9871, 429.5489, 285.7368, 223.8266],\n",
            "         [286.7827, 268.2927, 289.8473, 321.3940, 350.4237, 400.9783, 412.4311,\n",
            "          343.5270, 468.5952, 372.9651, 287.0841],\n",
            "         [277.4802, 291.8881, 292.6029, 320.8529, 367.2698, 316.6608, 337.2706,\n",
            "          310.0332, 370.2674, 503.4067, 371.7529],\n",
            "         [315.1207, 282.7256, 278.2457, 324.7496, 306.2084, 272.0829, 269.9077,\n",
            "          234.9640, 318.3032, 373.1082, 523.6038]]])\n",
            " (layer 7 > 0.001) 8 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[468.1474, 357.5946, 324.8550, 306.1958, 313.4670, 327.3254, 259.1747,\n",
            "          261.9634, 302.7126, 319.7155, 333.9464],\n",
            "         [328.4366, 348.9152, 457.1410, 353.7892, 315.6223, 260.5002, 253.9470,\n",
            "          247.3004, 293.5055, 321.9189, 305.2231],\n",
            "         [312.4542, 296.1351, 379.9868, 509.3858, 413.7223, 293.8877, 278.4601,\n",
            "          277.2796, 309.8935, 345.7020, 336.0813],\n",
            "         [327.2691, 291.9811, 332.1502, 382.7936, 505.4065, 369.9465, 311.6665,\n",
            "          304.3272, 311.7855, 366.9836, 338.2136],\n",
            "         [332.6789, 299.2475, 246.8038, 257.4952, 328.0576, 473.2903, 402.8110,\n",
            "          379.3825, 354.9028, 298.3117, 265.4233],\n",
            "         [253.1532, 260.3707, 303.8418, 241.7086, 292.2408, 340.7369, 382.5367,\n",
            "          334.3058, 430.8463, 294.3781, 256.2626],\n",
            "         [291.9766, 259.4641, 288.3787, 299.7299, 329.7506, 376.2768, 385.8653,\n",
            "          362.6091, 438.1734, 360.5197, 284.1941],\n",
            "         [288.3735, 283.6741, 293.9150, 289.4064, 341.0228, 289.3972, 318.2219,\n",
            "          326.8013, 350.5603, 495.6820, 354.9496],\n",
            "         [312.9781, 302.6927, 273.1298, 298.0555, 306.3531, 275.8891, 246.7663,\n",
            "          243.3453, 291.7570, 352.6367, 520.8616]]])\n",
            " (layer 7 > 0.0001) 9 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (4, 8), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94mlove\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[467.5442, 335.6942, 310.3883, 280.7450, 294.7032, 331.0946, 225.6256,\n",
            "          234.2574, 282.0596, 291.6984, 311.5692],\n",
            "         [337.0228, 375.0244, 459.8308, 367.5376, 310.0974, 271.0789, 223.4051,\n",
            "          227.7543, 289.4672, 302.0868, 315.2535],\n",
            "         [311.6381, 293.8466, 375.3868, 515.7750, 378.3253, 291.4935, 249.4583,\n",
            "          257.6729, 283.8223, 292.6512, 310.7877],\n",
            "         [342.7199, 295.0470, 319.0494, 378.9917, 497.4533, 377.5358, 301.6754,\n",
            "          285.6495, 314.1509, 353.7056, 333.3089],\n",
            "         [334.5905, 285.0661, 249.9767, 255.3754, 336.2397, 482.1795, 393.6951,\n",
            "          348.3189, 354.0410, 308.3067, 258.5172],\n",
            "         [253.1875, 292.6681, 288.4318, 261.9061, 316.4106, 369.1058, 376.0120,\n",
            "          336.7142, 415.6228, 296.3991, 246.7632],\n",
            "         [322.2174, 278.0394, 325.7896, 325.4405, 351.5359, 414.8789, 382.7246,\n",
            "          361.6619, 447.2450, 370.8347, 290.2693],\n",
            "         [302.3841, 294.2616, 304.0463, 318.9450, 362.5695, 336.9908, 316.9890,\n",
            "          325.1957, 371.7484, 531.8392, 340.5851],\n",
            "         [341.2289, 316.8240, 292.5293, 316.0502, 321.1171, 290.4767, 241.9429,\n",
            "          245.3448, 295.1630, 368.5550, 521.0837]]])\n",
            " (layer 7 > 1e-05) 8 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[466.7136, 365.4474, 331.6382, 307.7397, 312.3871, 310.5222, 248.6534,\n",
            "          261.4985, 288.1680, 320.3040, 342.9722],\n",
            "         [347.1906, 376.2769, 482.9264, 391.0813, 313.8388, 276.2148, 248.2562,\n",
            "          251.9160, 312.7579, 324.8607, 302.5087],\n",
            "         [298.9218, 290.0179, 381.4428, 530.9859, 412.9911, 299.5980, 266.5575,\n",
            "          267.4014, 291.2665, 325.2474, 333.5992],\n",
            "         [307.9266, 283.8496, 319.6859, 400.1301, 517.8985, 374.1520, 325.4723,\n",
            "          312.5301, 331.0552, 358.5569, 324.0173],\n",
            "         [325.2823, 318.8503, 270.0781, 277.5891, 358.3355, 487.5919, 406.8958,\n",
            "          382.8084, 388.8943, 325.3997, 277.7090],\n",
            "         [242.8341, 288.1610, 295.9639, 249.5054, 297.5721, 354.9519, 393.0800,\n",
            "          354.5976, 453.9171, 315.7477, 248.0605],\n",
            "         [271.5111, 259.1720, 292.2666, 294.6165, 313.6290, 382.2855, 378.6396,\n",
            "          347.9274, 424.8932, 364.6688, 280.4980],\n",
            "         [293.7280, 293.1880, 316.3240, 313.4838, 372.8069, 307.6703, 320.9981,\n",
            "          333.1518, 376.8606, 528.6427, 355.5219],\n",
            "         [329.0906, 318.5225, 283.4436, 303.2234, 317.2354, 269.7797, 241.4967,\n",
            "          235.5179, 280.2385, 365.1922, 514.4542]]])\n",
            " (layer 7 > 1e-06) 8 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (4, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94mlove\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[475.0945, 361.5297, 337.6761, 303.4540, 313.2858, 316.7287, 266.4414,\n",
            "          246.3908, 306.4807, 323.9381, 342.8737],\n",
            "         [336.0485, 365.6754, 445.6616, 368.7287, 319.2512, 279.3798, 258.7996,\n",
            "          234.6398, 297.1046, 320.8663, 293.7469],\n",
            "         [298.0523, 287.7284, 368.1175, 515.7432, 404.0137, 304.5839, 277.5888,\n",
            "          258.0304, 307.2383, 329.1600, 319.4965],\n",
            "         [321.8271, 290.7361, 319.9135, 389.3040, 505.5616, 360.2946, 306.7033,\n",
            "          294.9451, 325.0707, 362.8871, 338.5245],\n",
            "         [326.7965, 308.9376, 286.0443, 280.2680, 349.4053, 481.1657, 388.2883,\n",
            "          359.6434, 375.1534, 334.3458, 280.1096],\n",
            "         [239.8227, 270.1488, 294.1688, 231.7634, 272.0469, 363.2255, 386.9390,\n",
            "          338.3858, 421.6336, 289.0602, 239.2311],\n",
            "         [273.6685, 247.8926, 303.5572, 286.8206, 294.7763, 394.5138, 402.1356,\n",
            "          370.1655, 439.3781, 354.5688, 258.1376],\n",
            "         [284.6070, 298.0336, 306.5068, 318.4398, 348.4566, 337.5683, 337.9971,\n",
            "          346.6102, 376.7475, 506.3818, 340.7462],\n",
            "         [327.0776, 299.7074, 293.7058, 322.0046, 320.1695, 309.4045, 269.1070,\n",
            "          235.5001, 307.1669, 352.8033, 514.5525]]])\n",
            " (layer 7 > 1e-07) 8 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[466.4443, 334.8185, 295.6577, 306.3165, 289.6287, 304.5991, 252.5029,\n",
            "          240.4706, 286.0417, 319.9113, 332.7449],\n",
            "         [357.7785, 369.9663, 448.4015, 374.0840, 322.5600, 291.5249, 282.4250,\n",
            "          252.0306, 317.5111, 331.6862, 320.9961],\n",
            "         [307.3301, 297.9250, 366.7681, 517.6091, 420.1642, 299.2666, 272.7018,\n",
            "          239.0334, 286.0433, 328.6518, 330.2670],\n",
            "         [330.9767, 276.4008, 327.9367, 384.9241, 514.5457, 366.4828, 314.5150,\n",
            "          291.0203, 321.5448, 367.0722, 327.8446],\n",
            "         [348.4966, 298.1109, 269.4160, 283.8872, 339.7770, 469.7838, 396.7153,\n",
            "          351.7196, 368.2345, 316.3488, 288.5366],\n",
            "         [248.5328, 286.1963, 269.1775, 249.6455, 292.3556, 328.0569, 395.0215,\n",
            "          324.7187, 448.1717, 312.1110, 245.5365],\n",
            "         [295.0341, 268.3786, 292.7476, 312.4730, 314.2264, 376.4055, 378.0986,\n",
            "          350.9239, 446.7773, 359.2596, 271.2487],\n",
            "         [307.0436, 293.7924, 307.8807, 329.5758, 358.0986, 304.0853, 344.3097,\n",
            "          320.1460, 374.9937, 510.7573, 343.9293],\n",
            "         [337.5350, 299.5125, 288.3622, 323.8826, 312.6031, 285.5985, 256.3403,\n",
            "          233.6473, 300.5821, 363.0535, 521.4856]]])\n",
            " (layer 7 > 1e-08) 9 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (4, 8), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94mlove\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[473.5877, 366.5225, 337.3680, 313.8690, 311.7862, 321.8222, 304.1862,\n",
            "          273.6540, 315.9213, 334.7439, 342.1501],\n",
            "         [344.7213, 376.3528, 451.1390, 362.6188, 304.9712, 265.4628, 303.2511,\n",
            "          261.8745, 330.4521, 321.6954, 304.2082],\n",
            "         [330.3046, 336.8447, 391.0803, 527.4413, 400.2047, 278.7733, 299.1468,\n",
            "          279.4800, 304.5705, 324.4485, 324.5237],\n",
            "         [330.3293, 306.6050, 328.4550, 370.3834, 514.7466, 389.4452, 352.8113,\n",
            "          337.5896, 338.5528, 364.6839, 325.3264],\n",
            "         [364.4472, 338.0463, 291.9785, 285.6973, 358.8596, 475.0058, 427.0818,\n",
            "          370.9165, 390.9375, 342.3990, 294.1161],\n",
            "         [260.0946, 291.4904, 297.6440, 241.4724, 289.8381, 327.8508, 386.1970,\n",
            "          331.3587, 433.3013, 300.8010, 244.2118],\n",
            "         [300.2982, 270.0914, 313.2686, 320.5290, 337.8374, 378.5562, 407.7729,\n",
            "          334.8435, 439.2270, 371.2635, 293.3463],\n",
            "         [303.8534, 292.7993, 307.3340, 322.4638, 361.6086, 290.2944, 341.5098,\n",
            "          313.0340, 350.4143, 501.8585, 348.5292],\n",
            "         [312.0714, 288.6278, 289.8657, 309.9989, 310.7604, 259.1442, 245.7725,\n",
            "          240.4443, 299.3089, 352.6060, 517.4386]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[467.1777, 378.5198, 343.0139, 330.0563, 326.8326, 317.6731, 272.6787,\n",
            "          221.6321, 282.3734, 319.1365, 344.9507],\n",
            "         [371.3894, 380.6290, 466.6190, 386.9223, 343.3730, 281.7748, 260.2506,\n",
            "          235.4849, 292.4334, 325.9258, 322.0159],\n",
            "         [318.0409, 304.0143, 392.3563, 528.5181, 412.9941, 299.3255, 277.7723,\n",
            "          258.3841, 282.7524, 322.1220, 327.8548],\n",
            "         [331.1115, 284.9653, 319.6846, 389.3143, 501.9008, 361.5115, 301.5585,\n",
            "          271.8403, 286.9305, 330.5989, 327.1222],\n",
            "         [357.5398, 318.3087, 298.6766, 311.1920, 375.8988, 464.0902, 393.6617,\n",
            "          353.0663, 358.3082, 339.2491, 304.0815],\n",
            "         [287.0188, 306.3792, 328.5363, 278.6474, 334.6289, 355.4013, 394.7379,\n",
            "          328.8437, 427.6628, 322.2292, 268.1107],\n",
            "         [321.0836, 290.8966, 326.2362, 324.2326, 355.2075, 394.1128, 388.5806,\n",
            "          357.7054, 425.0997, 395.4355, 298.6482],\n",
            "         [332.2910, 321.6586, 324.8573, 344.2960, 374.8101, 330.4869, 348.0050,\n",
            "          311.5192, 364.8965, 495.5609, 384.2777],\n",
            "         [323.8057, 293.0290, 281.5588, 315.0998, 322.2595, 277.5905, 249.7180,\n",
            "          208.5115, 271.8676, 338.3099, 513.2836]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[466.5615, 375.8908, 352.9532, 305.6050, 310.0967, 301.2379, 245.0486,\n",
            "          244.5617, 299.2921, 289.4641, 334.0132],\n",
            "         [347.6057, 392.7520, 465.4905, 376.6358, 326.7958, 268.6644, 251.5337,\n",
            "          235.0307, 329.4985, 296.5958, 315.0136],\n",
            "         [320.8035, 348.6628, 376.7220, 529.4202, 384.0953, 278.8055, 281.4572,\n",
            "          257.7691, 303.2854, 298.7369, 326.5459],\n",
            "         [327.3829, 337.1356, 352.8054, 383.6448, 490.7211, 371.8825, 331.7672,\n",
            "          302.0162, 347.3685, 349.2327, 349.4701],\n",
            "         [349.2901, 318.7788, 297.8037, 287.8758, 356.0148, 473.5643, 391.2747,\n",
            "          355.5248, 380.5585, 298.5301, 285.2611],\n",
            "         [238.0848, 272.6232, 291.5640, 222.9029, 284.1154, 344.5761, 366.8139,\n",
            "          295.1159, 432.7259, 255.2291, 235.9769],\n",
            "         [300.0269, 306.0390, 317.8690, 314.9793, 332.9497, 372.6581, 369.2334,\n",
            "          341.9997, 433.3177, 336.7744, 278.2169],\n",
            "         [313.7921, 329.1975, 324.5405, 308.5036, 361.8584, 304.2751, 340.4869,\n",
            "          318.1049, 361.9504, 498.0089, 346.7800],\n",
            "         [323.4733, 317.5013, 302.7850, 303.0834, 319.5838, 258.5965, 238.4635,\n",
            "          229.1889, 290.3770, 361.9312, 525.5966]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[459.4343, 363.1799, 324.9814, 309.2677, 304.7796, 329.9800, 259.6768,\n",
            "          259.0182, 294.1951, 317.0239, 333.4960],\n",
            "         [337.9066, 365.9376, 440.0417, 367.3497, 298.1057, 289.6522, 259.9914,\n",
            "          251.6122, 305.3655, 302.8824, 307.4413],\n",
            "         [306.0464, 290.5141, 353.4678, 522.0736, 386.8285, 293.2769, 271.1461,\n",
            "          271.1232, 298.9667, 302.4096, 304.5112],\n",
            "         [327.8215, 294.8963, 308.3000, 387.1954, 487.0841, 372.0114, 313.9938,\n",
            "          329.2415, 335.4784, 348.2153, 313.6833],\n",
            "         [344.2709, 308.1020, 272.5013, 290.3210, 343.1577, 477.5142, 369.2762,\n",
            "          377.1377, 353.4848, 314.4331, 267.4012],\n",
            "         [241.5223, 295.1601, 288.6794, 254.8542, 278.9104, 344.7883, 350.9369,\n",
            "          319.5398, 403.8614, 289.4033, 241.1091],\n",
            "         [291.8499, 273.6978, 306.0306, 327.8351, 315.6945, 377.0029, 362.4600,\n",
            "          351.2495, 447.6163, 354.6078, 272.4739],\n",
            "         [292.0988, 296.5978, 313.8371, 325.0847, 353.9750, 316.7307, 313.6977,\n",
            "          323.7237, 361.2234, 513.0878, 351.1872],\n",
            "         [299.2510, 305.3512, 272.9616, 315.9262, 304.1866, 276.3801, 249.0358,\n",
            "          241.4123, 299.5352, 359.0216, 529.7607]]])\n",
            " (layer 7 > 1e-12) 8 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[475.9969, 354.4245, 346.2787, 285.5556, 297.0094, 308.0120, 257.8896,\n",
            "          249.8931, 305.5829, 305.8488, 323.3256],\n",
            "         [347.6744, 366.4552, 480.6788, 353.8887, 302.8755, 261.6367, 271.6463,\n",
            "          253.1425, 307.9297, 304.6310, 301.9679],\n",
            "         [298.0977, 283.8067, 383.0955, 537.7214, 401.9913, 286.0558, 290.0510,\n",
            "          269.0960, 315.3603, 313.7064, 314.1108],\n",
            "         [313.2534, 278.4607, 316.1248, 372.5764, 509.8284, 353.1237, 325.3195,\n",
            "          308.9100, 342.3285, 343.0491, 320.1237],\n",
            "         [320.5622, 293.2314, 277.2382, 264.2657, 354.6285, 470.4187, 416.1394,\n",
            "          369.3743, 389.6339, 324.8288, 276.5977],\n",
            "         [245.5787, 280.3346, 315.2357, 247.5024, 292.4193, 346.5356, 382.2565,\n",
            "          325.4052, 424.0424, 284.5146, 249.1781],\n",
            "         [285.7173, 257.6516, 299.3113, 284.4939, 315.8380, 367.9160, 371.2270,\n",
            "          364.4922, 451.4108, 362.9211, 276.5188],\n",
            "         [287.0373, 283.2967, 312.3795, 286.7806, 340.7616, 305.5392, 327.7949,\n",
            "          313.4081, 367.0525, 517.5341, 368.5227],\n",
            "         [302.6160, 275.1031, 288.0106, 285.7480, 294.2242, 270.5283, 248.8585,\n",
            "          236.1334, 290.4636, 359.4310, 509.4804]]])\n",
            " (layer 7 > 1e-13) 9 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (4, 8), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94mlove\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[473.7130, 355.6866, 331.7783, 311.0813, 323.2878, 310.3798, 257.4063,\n",
            "          246.4056, 299.3319, 307.9846, 321.4222],\n",
            "         [339.0615, 357.5843, 476.1519, 373.8330, 351.7090, 288.8071, 290.2017,\n",
            "          248.3549, 340.9158, 324.2157, 319.6899],\n",
            "         [312.3154, 298.6056, 372.7426, 518.5255, 395.1834, 295.5246, 298.4769,\n",
            "          261.7086, 312.9995, 318.5407, 334.8233],\n",
            "         [315.4719, 275.3418, 323.8196, 386.6454, 519.2830, 378.8537, 347.1539,\n",
            "          307.5153, 353.6248, 367.4585, 323.2110],\n",
            "         [309.9046, 265.1903, 232.1568, 247.5964, 327.9178, 467.6700, 404.8622,\n",
            "          363.9059, 405.0644, 319.9336, 252.6165],\n",
            "         [232.0511, 250.1980, 272.2024, 213.8708, 277.7375, 315.2448, 390.3918,\n",
            "          321.0916, 452.9597, 297.8206, 220.9105],\n",
            "         [284.7436, 247.2279, 295.5552, 294.2981, 329.4581, 374.4403, 399.3703,\n",
            "          359.4120, 467.9690, 369.5643, 253.8159],\n",
            "         [302.7901, 282.4598, 301.1792, 304.7377, 367.9877, 305.8919, 356.1588,\n",
            "          315.2706, 396.4858, 523.0643, 348.0460],\n",
            "         [327.8941, 298.1131, 298.3659, 313.2197, 312.9162, 269.5759, 268.3172,\n",
            "          220.9801, 307.9447, 373.4052, 519.8026]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[445.1961, 356.0982, 331.4173, 305.9442, 294.4846, 295.0298, 256.9278,\n",
            "          219.8667, 273.7444, 288.0748, 320.8779],\n",
            "         [343.7390, 370.1721, 452.8947, 364.1610, 301.6423, 260.8007, 238.1638,\n",
            "          226.5052, 288.7570, 299.2175, 293.0836],\n",
            "         [314.9568, 311.8873, 378.5163, 495.2459, 407.8877, 306.1545, 262.8784,\n",
            "          250.3131, 287.5715, 323.3704, 316.5711],\n",
            "         [275.7968, 266.2668, 278.3788, 357.3344, 495.6245, 336.9149, 279.8406,\n",
            "          253.3151, 270.3481, 314.0000, 277.0417],\n",
            "         [315.0724, 300.2778, 258.6029, 263.3986, 333.4094, 455.9651, 365.2183,\n",
            "          340.9223, 361.5102, 305.1515, 241.6636],\n",
            "         [205.0919, 258.2824, 253.6414, 219.7705, 287.0927, 350.6296, 347.1491,\n",
            "          289.2654, 425.3040, 279.1683, 206.5500],\n",
            "         [279.0685, 275.7249, 288.8839, 276.0822, 287.3440, 361.7974, 349.7017,\n",
            "          292.4051, 419.4129, 336.2233, 248.7179],\n",
            "         [286.9158, 289.9180, 308.0797, 322.6812, 340.0476, 297.6049, 300.1425,\n",
            "          272.9956, 322.2685, 465.8589, 323.2503],\n",
            "         [293.1657, 288.8915, 279.1345, 311.3170, 301.5998, 238.6744, 244.1368,\n",
            "          197.2547, 233.1203, 303.8997, 504.3937]]])\n",
            " (layer 8 > 0.001) 9 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (4, 8), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94mlove\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[430.2527, 335.0168, 311.0406, 288.8061, 288.1063, 315.7715, 258.1857,\n",
            "          236.1913, 288.7160, 278.3435, 320.1232],\n",
            "         [332.9781, 340.6602, 434.6993, 357.6670, 288.3969, 278.1351, 275.5100,\n",
            "          239.5831, 285.2183, 288.6916, 299.1925],\n",
            "         [285.2173, 281.0948, 352.0692, 502.8086, 370.5289, 305.9014, 300.0349,\n",
            "          269.6256, 291.7065, 306.4284, 310.8259],\n",
            "         [270.6489, 230.8999, 283.1464, 365.5082, 478.0636, 334.6572, 289.2343,\n",
            "          285.0910, 268.8595, 297.1188, 286.5435],\n",
            "         [303.5346, 283.9136, 251.5645, 272.7059, 306.2232, 435.9235, 361.5540,\n",
            "          357.1718, 338.1168, 276.4939, 227.4642],\n",
            "         [214.9943, 262.5281, 290.2878, 230.6603, 275.0114, 336.9491, 365.4187,\n",
            "          339.4546, 369.5389, 245.6856, 208.9513],\n",
            "         [257.7076, 240.4048, 274.3027, 295.1530, 305.1485, 370.6914, 364.0590,\n",
            "          341.3972, 421.3128, 317.1293, 254.7881],\n",
            "         [283.5520, 262.6204, 289.1484, 335.6154, 340.2842, 332.2402, 342.3717,\n",
            "          311.2211, 349.3814, 467.7197, 309.0529],\n",
            "         [296.0007, 261.6895, 264.1600, 300.3987, 296.0265, 258.3627, 231.8810,\n",
            "          197.8675, 246.9095, 288.4374, 466.0925]]])\n",
            " (layer 8 > 0.0001) 9 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (4, 6), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94mlove\u001b[0m===\u001b[1m\u001b[91mt\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[422.3324, 365.7937, 336.9249, 311.7421, 283.5143, 298.1779, 265.9985,\n",
            "          234.8972, 293.6662, 298.5012, 310.7155],\n",
            "         [323.8993, 366.8024, 416.7870, 357.8906, 290.6259, 266.0509, 263.4002,\n",
            "          217.7580, 292.3140, 285.7074, 283.5117],\n",
            "         [275.9979, 288.7384, 348.1425, 514.3655, 380.5560, 282.7743, 269.8338,\n",
            "          250.1978, 278.0524, 305.5934, 320.2562],\n",
            "         [286.6060, 279.3609, 310.9786, 367.4875, 476.1129, 369.0880, 340.1098,\n",
            "          318.9012, 323.6295, 330.6702, 301.1743],\n",
            "         [295.4894, 300.3928, 266.5248, 286.9697, 334.0026, 457.8060, 379.3607,\n",
            "          346.1810, 354.8439, 270.8991, 241.7851],\n",
            "         [205.7594, 256.8191, 273.2075, 248.0831, 285.4847, 336.5659, 391.6581,\n",
            "          323.7589, 416.4381, 261.1470, 197.3637],\n",
            "         [278.3199, 263.3951, 295.4843, 265.1956, 298.0284, 351.7471, 359.6967,\n",
            "          309.1440, 408.2479, 315.7343, 253.4945],\n",
            "         [291.0752, 288.8951, 305.8318, 321.7466, 337.7859, 301.9987, 342.4483,\n",
            "          290.9263, 351.3120, 465.7029, 329.3466],\n",
            "         [301.7824, 268.8278, 273.2745, 290.6658, 275.5377, 252.1924, 231.3282,\n",
            "          211.5705, 253.7375, 323.0950, 502.1030]]])\n",
            " (layer 8 > 1e-05) 9 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (4, 8), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94mlove\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[447.4189, 370.5746, 341.6075, 291.4303, 275.5577, 295.9605, 269.0261,\n",
            "          248.5543, 280.8096, 295.6521, 315.0258],\n",
            "         [316.2547, 375.9432, 458.7990, 371.2588, 286.1579, 266.0472, 281.6738,\n",
            "          253.5211, 294.0706, 292.9446, 291.2264],\n",
            "         [289.6950, 308.9348, 369.0978, 496.4763, 390.7062, 274.4588, 299.3043,\n",
            "          261.4197, 298.8043, 331.1172, 305.7664],\n",
            "         [290.3086, 294.7357, 317.9738, 382.5752, 473.8830, 351.0007, 333.6956,\n",
            "          294.0957, 327.1583, 368.2834, 323.5193],\n",
            "         [279.1929, 300.3550, 250.3809, 265.9877, 315.1346, 440.6056, 373.7953,\n",
            "          330.0250, 348.2823, 290.7602, 222.8700],\n",
            "         [194.0157, 266.6126, 286.3925, 233.4639, 291.4580, 342.7332, 381.5367,\n",
            "          309.9187, 414.5422, 299.2101, 198.4686],\n",
            "         [253.2225, 253.2639, 286.3806, 271.4747, 288.3920, 374.4335, 377.9041,\n",
            "          306.8746, 416.6810, 330.5036, 224.0426],\n",
            "         [242.8595, 273.2211, 285.3417, 297.3299, 329.2333, 302.8936, 324.1217,\n",
            "          284.3508, 338.7461, 484.6649, 307.3418],\n",
            "         [280.5399, 273.9451, 271.6323, 295.5469, 263.4314, 234.3173, 226.9992,\n",
            "          218.1207, 245.0020, 299.5073, 492.7454]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[438.1776, 370.8942, 330.3866, 298.0812, 280.4046, 309.2228, 227.7652,\n",
            "          225.7406, 288.0628, 300.3293, 318.7326],\n",
            "         [331.8672, 356.2590, 423.4597, 368.2887, 294.6877, 263.0305, 250.6510,\n",
            "          213.4977, 295.1242, 292.0251, 294.7322],\n",
            "         [279.8835, 293.5240, 345.5011, 495.9181, 388.4091, 270.7460, 248.3244,\n",
            "          227.4168, 278.6414, 314.1960, 305.8770],\n",
            "         [299.0207, 266.4494, 307.9529, 355.8806, 481.8762, 345.0065, 297.5416,\n",
            "          291.8014, 298.0159, 335.7554, 294.3490],\n",
            "         [324.1336, 293.2146, 256.7882, 261.0270, 325.6627, 444.5061, 373.2339,\n",
            "          342.1358, 345.9997, 296.6622, 234.8981],\n",
            "         [221.7158, 263.1550, 282.2059, 227.9291, 272.1154, 335.8493, 352.5587,\n",
            "          323.3716, 405.5486, 286.5638, 212.6628],\n",
            "         [281.3372, 246.2199, 269.6528, 262.8321, 260.0433, 342.8193, 335.4759,\n",
            "          282.6439, 409.2791, 325.3395, 231.2670],\n",
            "         [283.1072, 273.0576, 287.2547, 289.0770, 330.0465, 288.3470, 293.5859,\n",
            "          256.7244, 337.5563, 475.6347, 320.3958],\n",
            "         [305.8214, 263.0669, 256.6394, 285.3587, 277.3978, 256.1092, 217.8557,\n",
            "          188.1108, 270.0379, 298.7773, 506.5161]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[441.3984, 337.8228, 327.2979, 279.5602, 268.5579, 304.7817, 237.0487,\n",
            "          257.8833, 271.4328, 277.4995, 290.6999],\n",
            "         [340.1701, 359.6685, 434.2777, 328.6079, 267.4979, 252.7872, 235.2106,\n",
            "          248.6903, 282.7862, 299.5053, 290.7904],\n",
            "         [298.5536, 274.9718, 367.1385, 462.7763, 348.8383, 262.2028, 245.5215,\n",
            "          244.5576, 266.8890, 294.5757, 302.5843],\n",
            "         [320.5656, 265.1686, 317.3108, 348.6431, 441.7343, 339.9354, 317.2091,\n",
            "          292.5624, 315.7191, 343.2173, 298.5618],\n",
            "         [319.7335, 293.9313, 251.3302, 249.9242, 317.5987, 436.7875, 386.6182,\n",
            "          366.0362, 354.4164, 288.9189, 221.2893],\n",
            "         [222.6725, 276.8963, 271.1898, 211.7680, 255.7936, 346.6764, 363.1345,\n",
            "          311.0844, 402.1236, 254.9284, 184.5974],\n",
            "         [272.9978, 246.5768, 275.1537, 269.4197, 277.3838, 356.7993, 345.2719,\n",
            "          313.2282, 415.9400, 329.2663, 242.1511],\n",
            "         [288.9320, 260.1143, 278.4965, 281.0572, 296.6200, 280.8398, 288.7444,\n",
            "          273.0231, 336.0454, 465.8571, 282.9852],\n",
            "         [295.2874, 233.9029, 244.8734, 274.9413, 258.8777, 244.1416, 210.5131,\n",
            "          217.0871, 248.5052, 278.9521, 477.0643]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[431.0287, 355.2478, 334.3117, 294.1426, 297.8492, 265.9391, 222.5342,\n",
            "          198.6626, 273.2631, 300.0750, 317.7679],\n",
            "         [335.1083, 366.2161, 450.1633, 345.1306, 296.4548, 266.4844, 233.7135,\n",
            "          205.5229, 284.9250, 305.2390, 299.0642],\n",
            "         [291.1021, 275.7242, 370.3308, 494.9993, 377.8282, 282.2130, 248.5570,\n",
            "          227.8953, 275.2703, 322.1639, 311.2612],\n",
            "         [277.3771, 245.5683, 305.7704, 357.7721, 483.6648, 335.0414, 277.7807,\n",
            "          251.6975, 280.2041, 311.3789, 275.3333],\n",
            "         [295.0175, 285.8893, 278.2025, 273.5919, 359.5555, 431.1246, 366.7525,\n",
            "          316.1125, 357.5431, 319.7705, 241.4375],\n",
            "         [227.0968, 257.7639, 283.2122, 251.3136, 307.5067, 329.9204, 329.0817,\n",
            "          270.3187, 401.0756, 295.8396, 211.8209],\n",
            "         [267.8146, 247.3197, 286.9028, 270.5050, 320.9948, 351.6266, 317.6725,\n",
            "          278.2686, 389.1011, 326.8112, 231.9144],\n",
            "         [255.8364, 248.4333, 288.7903, 317.4202, 340.8761, 276.6196, 280.9241,\n",
            "          261.3985, 321.9964, 470.9863, 296.8773],\n",
            "         [298.6824, 272.7090, 281.6493, 303.7343, 295.0455, 227.6736, 216.4911,\n",
            "          196.4735, 259.4584, 294.8355, 487.8429]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[416.8540, 317.2794, 328.0760, 297.1223, 293.5988, 277.5602, 264.2558,\n",
            "          234.0023, 283.1217, 297.1448, 294.6681],\n",
            "         [334.5963, 345.7110, 442.9713, 366.2008, 315.1124, 249.9485, 252.9961,\n",
            "          227.5685, 287.9557, 311.3372, 289.2956],\n",
            "         [273.5769, 267.7340, 362.6339, 474.3998, 387.1136, 268.8294, 270.6259,\n",
            "          245.1231, 266.9601, 301.3397, 293.1685],\n",
            "         [289.9666, 247.0867, 318.3047, 365.5510, 476.5994, 345.2967, 303.6453,\n",
            "          280.1928, 277.7614, 324.7715, 293.6855],\n",
            "         [307.5985, 263.7702, 261.0163, 254.4135, 329.8274, 442.9294, 375.4051,\n",
            "          329.5618, 354.9909, 300.7897, 244.1560],\n",
            "         [219.1171, 243.6121, 271.6247, 234.1849, 287.8998, 315.0172, 350.8922,\n",
            "          299.5829, 392.1447, 271.0681, 217.6017],\n",
            "         [267.1808, 223.4509, 290.9910, 289.1394, 313.3515, 356.3260, 355.5642,\n",
            "          304.7645, 398.4894, 313.1672, 241.8906],\n",
            "         [253.7962, 237.6872, 279.2765, 291.8270, 325.6976, 288.3356, 316.8597,\n",
            "          283.9143, 338.8199, 471.5957, 284.1940],\n",
            "         [270.1415, 234.2347, 261.0229, 288.3844, 279.6339, 227.7334, 235.1835,\n",
            "          215.1378, 237.3274, 293.0425, 498.6316]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[446.9423, 354.6668, 340.9842, 330.5204, 305.6757, 305.2472, 263.3133,\n",
            "          236.0932, 281.7411, 301.5317, 321.2428],\n",
            "         [350.9235, 381.6965, 451.5162, 366.3181, 310.8650, 265.1174, 268.3475,\n",
            "          223.3145, 287.9006, 292.1044, 304.0738],\n",
            "         [312.7444, 311.4385, 360.9753, 506.8904, 405.3466, 306.2764, 283.6586,\n",
            "          249.2458, 275.9156, 324.0679, 313.2201],\n",
            "         [302.0794, 261.0226, 302.1150, 377.9772, 498.7805, 355.2344, 327.5775,\n",
            "          280.8817, 286.5935, 336.5881, 287.5471],\n",
            "         [331.2209, 280.6255, 270.1425, 279.3466, 344.3047, 459.2850, 390.3888,\n",
            "          341.0529, 349.3146, 334.2281, 244.2815],\n",
            "         [228.3314, 235.5621, 262.5692, 229.2653, 280.8953, 339.0373, 345.3560,\n",
            "          310.3955, 408.8391, 306.8078, 203.5407],\n",
            "         [267.7557, 230.6561, 276.7120, 269.6332, 296.5831, 358.4337, 350.4180,\n",
            "          312.8765, 406.2685, 344.4383, 231.7298],\n",
            "         [283.3641, 262.3891, 295.3573, 311.9631, 331.5237, 280.9980, 311.0684,\n",
            "          268.8825, 338.2830, 470.5938, 297.8026],\n",
            "         [310.3134, 283.2895, 266.9755, 311.6402, 312.2093, 251.6180, 246.0896,\n",
            "          204.0722, 270.4770, 314.8924, 487.4677]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[443.1643, 367.7795, 336.5720, 314.3992, 300.4753, 302.9063, 258.8050,\n",
            "          231.1793, 287.1350, 293.5362, 326.0098],\n",
            "         [347.4336, 377.9165, 465.8070, 387.4625, 321.6209, 284.8062, 265.2197,\n",
            "          231.4570, 290.5116, 309.8805, 313.0285],\n",
            "         [310.8453, 293.9022, 392.6067, 497.2958, 401.0458, 294.2818, 272.3409,\n",
            "          255.9878, 268.3813, 316.8989, 318.9390],\n",
            "         [297.2260, 250.2076, 305.9062, 350.9210, 507.2939, 357.8964, 302.4018,\n",
            "          294.3931, 282.7531, 337.8094, 318.1373],\n",
            "         [309.9054, 299.4506, 253.0444, 243.6838, 319.8876, 451.3868, 374.1397,\n",
            "          354.4010, 357.9386, 292.3235, 248.2118],\n",
            "         [226.4804, 263.6206, 267.2823, 235.1011, 281.7795, 353.4374, 366.9816,\n",
            "          332.9622, 406.7070, 294.5716, 223.1851],\n",
            "         [281.6909, 242.1779, 275.7453, 276.2213, 291.6465, 340.0319, 345.4820,\n",
            "          313.7892, 404.4738, 340.7874, 264.0698],\n",
            "         [284.1188, 263.0442, 298.8481, 311.0494, 343.6477, 304.1778, 314.8659,\n",
            "          282.0321, 327.7600, 474.2296, 321.0183],\n",
            "         [290.2354, 274.8279, 277.5968, 311.8241, 296.2883, 232.3953, 214.9368,\n",
            "          194.6939, 228.6922, 312.8669, 506.0363]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[415.5414, 340.2062, 336.3185, 302.9255, 287.2988, 316.5590, 231.4500,\n",
            "          248.3662, 276.4145, 278.2593, 291.5987],\n",
            "         [335.5980, 362.8034, 436.6351, 365.9516, 280.4039, 256.8162, 236.4341,\n",
            "          243.6912, 285.6629, 299.6941, 296.5707],\n",
            "         [270.5710, 301.9082, 363.5793, 491.2679, 373.4275, 257.8426, 244.4723,\n",
            "          249.1677, 274.6118, 300.2747, 304.2031],\n",
            "         [267.7249, 248.5811, 295.1045, 351.4274, 496.6249, 346.7086, 277.5238,\n",
            "          281.4395, 273.0305, 317.7235, 284.6735],\n",
            "         [302.1567, 272.2984, 272.3715, 271.5647, 327.9970, 451.9661, 360.4298,\n",
            "          361.1419, 343.0981, 289.3315, 228.2200],\n",
            "         [213.4795, 236.1032, 285.7423, 242.0250, 307.8197, 344.1407, 343.6248,\n",
            "          332.3039, 406.2604, 278.6798, 206.6410],\n",
            "         [247.5433, 219.9498, 293.4021, 278.2353, 287.0466, 361.4791, 324.9739,\n",
            "          325.2182, 412.5031, 324.2968, 222.3716],\n",
            "         [267.1085, 230.7206, 285.1524, 302.3164, 321.9189, 285.2753, 275.5004,\n",
            "          285.8026, 323.5115, 479.6487, 288.5011],\n",
            "         [296.7202, 282.3648, 292.4626, 304.7990, 282.7039, 250.6913, 224.7801,\n",
            "          220.0307, 265.3383, 301.8557, 485.2762]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[437.3599, 346.5007, 351.0967, 282.9589, 271.5456, 296.4490, 233.7569,\n",
            "          198.1331, 276.5846, 302.3982, 318.8093],\n",
            "         [350.8691, 373.3451, 443.0657, 353.7497, 296.6061, 267.1864, 257.1480,\n",
            "          212.5472, 301.8038, 309.3662, 312.9669],\n",
            "         [313.8850, 325.1480, 379.2370, 468.1188, 373.3679, 303.8051, 275.1463,\n",
            "          236.2969, 286.1286, 327.9576, 318.1140],\n",
            "         [329.1766, 301.3302, 357.2466, 402.4158, 472.2393, 366.9422, 307.0326,\n",
            "          265.0643, 317.6583, 350.5211, 313.4428],\n",
            "         [297.8209, 301.5569, 276.8222, 281.2137, 303.0665, 446.0005, 352.9692,\n",
            "          317.3596, 330.3235, 300.9731, 229.5266],\n",
            "         [245.5616, 284.3521, 293.5891, 242.5699, 280.3586, 348.8480, 363.8027,\n",
            "          284.0257, 408.5975, 308.2537, 222.5936],\n",
            "         [251.4419, 235.4779, 278.8358, 272.3417, 241.8785, 347.3744, 327.0753,\n",
            "          254.1910, 387.4977, 312.9029, 228.4354],\n",
            "         [287.4531, 288.4081, 311.5017, 316.7032, 320.5688, 312.9489, 299.0156,\n",
            "          267.0828, 341.7957, 469.3198, 313.0218],\n",
            "         [277.5557, 251.5226, 267.6056, 296.9384, 272.6123, 259.6703, 216.9157,\n",
            "          191.3549, 260.3918, 337.4789, 475.9102]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[600.4792, 503.0208, 470.7986, 442.7167, 432.7923, 436.6501, 470.2502,\n",
            "          419.6727, 443.3827, 446.7081, 476.9282],\n",
            "         [501.3137, 500.4456, 578.6531, 505.6822, 450.2315, 420.5178, 468.0588,\n",
            "          420.8210, 456.9787, 446.8902, 441.4147],\n",
            "         [480.4693, 459.2551, 509.2952, 614.0057, 530.4875, 442.4163, 486.5308,\n",
            "          445.4513, 464.4284, 475.3031, 472.0224],\n",
            "         [430.0836, 404.2295, 444.9395, 483.5077, 619.4357, 478.6602, 485.5681,\n",
            "          440.6697, 463.7295, 470.3701, 435.6650],\n",
            "         [457.2495, 426.3289, 394.9010, 407.9028, 462.2560, 563.5607, 536.4935,\n",
            "          513.4075, 495.5961, 419.9901, 390.3045],\n",
            "         [374.8707, 407.1685, 393.7857, 383.3636, 411.1575, 453.2663, 497.4830,\n",
            "          457.1226, 516.3843, 389.4016, 361.9349],\n",
            "         [413.3025, 386.8516, 420.6353, 434.3123, 438.2971, 460.7175, 488.3753,\n",
            "          452.4550, 524.7885, 449.7908, 396.7946],\n",
            "         [454.7852, 430.8412, 445.3070, 456.9652, 467.1829, 430.8891, 474.0833,\n",
            "          438.7560, 467.5119, 624.8343, 475.4172],\n",
            "         [429.6752, 364.8178, 394.0083, 430.9794, 392.3560, 353.2976, 395.9466,\n",
            "          352.9450, 403.5302, 442.3965, 632.5527]]])\n",
            " (layer 9 > 0.001) 8 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[601.1460, 492.7626, 470.2500, 450.7836, 447.7947, 477.5151, 400.5356,\n",
            "          402.6236, 429.0786, 440.1707, 466.3487],\n",
            "         [495.1993, 476.3660, 574.7284, 515.8054, 459.7670, 434.5806, 403.2221,\n",
            "          398.0951, 442.2705, 460.1421, 425.3560],\n",
            "         [418.6770, 394.6256, 482.4938, 598.1703, 537.2695, 424.3639, 395.4114,\n",
            "          382.4524, 412.1490, 468.7496, 427.5700],\n",
            "         [414.6656, 390.7689, 434.9206, 492.2162, 614.4282, 496.9634, 420.1644,\n",
            "          410.3435, 426.6480, 461.4604, 402.0878],\n",
            "         [465.5530, 449.4590, 394.9773, 417.8219, 485.1856, 592.1287, 478.1343,\n",
            "          461.4352, 482.6098, 426.7241, 382.9329],\n",
            "         [407.1591, 416.2422, 419.2702, 398.5455, 460.4763, 483.4832, 485.3972,\n",
            "          455.9518, 558.4366, 421.3097, 359.9660],\n",
            "         [433.9335, 389.5798, 440.0675, 447.0656, 467.7324, 507.9822, 487.2312,\n",
            "          468.6433, 549.4064, 491.0246, 397.4146],\n",
            "         [422.4261, 386.6147, 425.6447, 448.2359, 469.5318, 429.6879, 447.5386,\n",
            "          434.2453, 478.7642, 589.3952, 420.8733],\n",
            "         [471.9451, 424.1945, 417.9810, 459.8515, 452.7395, 414.5283, 385.1201,\n",
            "          389.5875, 411.8189, 478.8755, 639.7397]]])\n",
            " (layer 9 > 0.0001) 9 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (4, 8), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94mlove\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[622.0652, 526.5475, 492.5773, 460.5210, 404.4846, 460.5692, 438.9411,\n",
            "          452.1171, 445.4292, 443.8900, 468.3104],\n",
            "         [503.7292, 512.8102, 593.4266, 512.8671, 436.1155, 430.0355, 428.6774,\n",
            "          430.9617, 463.4947, 469.1363, 457.8059],\n",
            "         [467.8380, 462.6614, 533.2053, 640.9407, 516.2092, 440.9732, 449.3717,\n",
            "          445.8042, 440.4667, 472.9073, 469.4519],\n",
            "         [442.5380, 404.9114, 474.6454, 520.6356, 609.9111, 466.8856, 447.6650,\n",
            "          445.3364, 423.8608, 474.7745, 443.2499],\n",
            "         [438.3088, 421.9914, 390.2364, 394.0266, 447.4108, 574.6595, 493.2636,\n",
            "          473.9749, 432.3386, 425.3266, 352.7855],\n",
            "         [389.8740, 405.9212, 436.8019, 404.5933, 418.3951, 475.5277, 493.1752,\n",
            "          464.1839, 535.6400, 428.3226, 368.1235],\n",
            "         [455.3533, 416.4989, 456.4009, 459.9653, 421.4270, 493.8321, 478.1457,\n",
            "          495.9163, 509.5200, 471.6196, 398.1866],\n",
            "         [435.5170, 425.3078, 474.9412, 475.3708, 462.4321, 431.5528, 446.3794,\n",
            "          463.9564, 485.7141, 612.1108, 457.5401],\n",
            "         [458.9606, 407.2299, 445.9169, 454.7427, 417.0979, 390.9811, 389.5756,\n",
            "          396.9986, 409.5804, 461.1335, 645.6597]]])\n",
            " (layer 9 > 1e-05) 8 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (4, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94mlove\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[604.9963, 513.5292, 472.8133, 465.0919, 443.7981, 458.5305, 389.8900,\n",
            "          425.1736, 458.9955, 439.6764, 446.1312],\n",
            "         [521.9097, 506.9329, 577.0259, 523.5474, 450.8071, 413.3092, 388.3527,\n",
            "          406.5326, 478.0743, 453.2278, 435.1910],\n",
            "         [480.7696, 455.6229, 514.1737, 635.6833, 544.2021, 462.7066, 422.2109,\n",
            "          457.1091, 478.3373, 469.6996, 425.1515],\n",
            "         [491.6325, 455.4505, 478.8736, 541.3550, 632.1622, 515.2646, 460.5266,\n",
            "          491.5444, 511.7755, 508.5742, 454.6145],\n",
            "         [486.6895, 470.2220, 414.9555, 441.7912, 488.1497, 588.1367, 501.9515,\n",
            "          488.7765, 507.7142, 438.2059, 391.5515],\n",
            "         [422.0309, 433.6558, 426.5074, 419.1472, 470.6367, 485.1431, 474.3895,\n",
            "          482.0110, 554.4644, 426.4911, 384.7170],\n",
            "         [463.7395, 432.1778, 439.8322, 453.4561, 459.4514, 504.5611, 472.9814,\n",
            "          477.7637, 575.7369, 474.7905, 400.0712],\n",
            "         [422.7243, 403.5294, 420.3864, 445.1215, 465.8895, 414.2986, 400.7816,\n",
            "          411.7593, 472.6143, 632.3779, 440.8920],\n",
            "         [471.3784, 432.5500, 422.6367, 461.7094, 429.4654, 402.8675, 353.7035,\n",
            "          388.2904, 443.1833, 476.1176, 650.0111]]])\n",
            " (layer 9 > 1e-06) 8 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[623.4803, 520.8080, 511.2146, 461.1562, 430.8716, 451.6891, 394.9069,\n",
            "          404.5695, 460.7859, 451.4517, 480.8753],\n",
            "         [496.3136, 514.1110, 564.1035, 536.7764, 432.7932, 436.2377, 405.6188,\n",
            "          411.1517, 474.6230, 456.7510, 444.3814],\n",
            "         [424.1103, 431.8289, 482.4129, 627.7448, 508.5024, 412.8809, 408.0464,\n",
            "          406.4068, 434.1302, 441.5606, 411.9301],\n",
            "         [417.2603, 406.2553, 436.0726, 519.2637, 594.1640, 458.9125, 409.5429,\n",
            "          416.6382, 457.6708, 444.7733, 397.6747],\n",
            "         [456.8985, 440.9799, 422.5918, 425.1154, 468.8311, 579.0828, 497.7220,\n",
            "          466.7684, 511.6596, 422.9189, 364.7761],\n",
            "         [369.8876, 404.2197, 422.9554, 417.3274, 437.8062, 459.4761, 457.6769,\n",
            "          440.8114, 542.0380, 395.2446, 338.8621],\n",
            "         [433.6305, 410.6222, 457.5789, 454.8979, 432.6899, 500.6282, 471.8567,\n",
            "          471.7330, 565.3264, 461.1680, 378.3958],\n",
            "         [469.7568, 436.9223, 458.4487, 489.9127, 460.3467, 449.8368, 448.9061,\n",
            "          458.8238, 502.7731, 598.6483, 459.7687],\n",
            "         [476.5331, 424.1893, 417.0848, 445.6621, 401.8524, 385.6957, 362.2761,\n",
            "          361.0660, 414.8724, 467.0674, 639.3470]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[569.7235, 477.5853, 479.1712, 444.8294, 441.1564, 451.7527, 437.4609,\n",
            "          404.5576, 443.5438, 447.3062, 467.3932],\n",
            "         [493.9734, 478.4208, 569.0377, 522.6127, 457.7509, 411.0939, 419.4723,\n",
            "          388.7207, 438.3262, 468.0249, 463.7514],\n",
            "         [423.6530, 416.4008, 473.7138, 616.4705, 497.0352, 413.2558, 423.0826,\n",
            "          385.4770, 416.8551, 449.7646, 443.0095],\n",
            "         [442.7340, 405.1759, 438.1056, 481.0774, 605.9990, 476.0898, 459.0893,\n",
            "          430.1436, 436.1357, 478.1324, 445.9298],\n",
            "         [467.9024, 447.2616, 372.6447, 391.4221, 458.3746, 559.4343, 489.2490,\n",
            "          502.2388, 479.7938, 431.7786, 392.5997],\n",
            "         [385.7454, 412.0791, 404.3882, 373.3998, 404.7503, 462.2092, 478.7494,\n",
            "          455.8638, 518.8457, 407.2704, 380.2853],\n",
            "         [460.0500, 435.6546, 436.8241, 446.0638, 452.9420, 503.7891, 514.5266,\n",
            "          489.7470, 551.5735, 494.6656, 439.1637],\n",
            "         [432.6938, 420.8091, 444.8710, 445.5359, 457.7242, 423.1602, 474.8554,\n",
            "          425.8329, 480.7164, 620.9133, 465.9241],\n",
            "         [433.3052, 387.4864, 408.5101, 427.6173, 418.5587, 384.3584, 381.6171,\n",
            "          354.7993, 398.8213, 432.5586, 636.7186]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[616.0569, 516.6206, 483.1248, 468.8637, 453.4034, 442.1318, 377.6376,\n",
            "          391.6983, 410.8851, 442.5218, 504.1530],\n",
            "         [516.6221, 507.6566, 573.1398, 526.6807, 473.7091, 429.0475, 419.1574,\n",
            "          405.6764, 438.3387, 460.3546, 498.3520],\n",
            "         [445.9210, 427.5963, 522.6381, 623.2927, 520.9277, 422.0269, 397.7510,\n",
            "          378.3717, 419.2172, 460.2948, 473.6903],\n",
            "         [464.1392, 441.7997, 448.8572, 517.3156, 595.0625, 474.2626, 418.4825,\n",
            "          411.9318, 417.4095, 465.4639, 466.3902],\n",
            "         [427.5042, 411.8408, 362.0953, 375.3403, 452.2792, 553.5203, 442.8434,\n",
            "          446.1792, 444.1417, 397.1128, 378.0948],\n",
            "         [373.5143, 390.0467, 407.0790, 379.3936, 436.6978, 472.4600, 469.9446,\n",
            "          435.5977, 526.8081, 396.2768, 378.4232],\n",
            "         [467.9726, 410.2306, 452.0150, 449.0377, 449.8599, 491.9557, 479.5525,\n",
            "          462.5154, 550.4565, 463.8798, 447.9330],\n",
            "         [437.2256, 408.7608, 435.9584, 442.6985, 486.3975, 445.0593, 427.6611,\n",
            "          409.1366, 448.7273, 626.5875, 476.2666],\n",
            "         [468.9535, 414.4800, 401.3552, 445.6194, 418.0770, 405.4995, 335.7045,\n",
            "          350.4182, 382.0342, 449.0001, 654.9779]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[594.7346, 505.4130, 497.1335, 464.6721, 447.1725, 458.2256, 421.9721,\n",
            "          364.1034, 432.5309, 464.5672, 502.9396],\n",
            "         [493.9938, 487.5952, 585.3575, 535.3942, 464.2245, 433.9374, 431.6839,\n",
            "          371.9942, 441.0728, 478.9391, 483.2201],\n",
            "         [425.2075, 411.3339, 501.0112, 624.1328, 502.7509, 418.3549, 405.9633,\n",
            "          349.3668, 391.1642, 465.4674, 445.5847],\n",
            "         [419.9981, 389.5417, 436.5775, 495.1938, 600.5050, 475.7383, 431.4936,\n",
            "          369.4338, 406.8076, 474.1235, 415.2086],\n",
            "         [420.6048, 421.4926, 400.8650, 416.1233, 445.9646, 567.2656, 488.7050,\n",
            "          430.0380, 462.6894, 439.1462, 398.2790],\n",
            "         [371.5555, 398.3584, 430.5206, 390.7323, 422.3343, 474.1803, 487.1666,\n",
            "          414.7156, 534.2208, 412.6788, 375.1508],\n",
            "         [451.9882, 428.9985, 466.8818, 470.3486, 447.2634, 491.2393, 496.4471,\n",
            "          418.7335, 523.0914, 487.1172, 442.4887],\n",
            "         [449.1595, 444.5656, 474.1174, 490.9445, 476.1696, 452.9289, 455.0787,\n",
            "          394.0117, 471.8069, 618.4709, 484.7219],\n",
            "         [446.6464, 432.3823, 433.0011, 464.1489, 448.4904, 415.5033, 407.4843,\n",
            "          335.6484, 406.7895, 467.4681, 648.5751]]])\n",
            " (layer 9 > 1e-10) 9 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (4, 8), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94mlove\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[612.9377, 517.0392, 489.2282, 461.8072, 466.8838, 468.8336, 443.9488,\n",
            "          420.7427, 453.3266, 463.7899, 482.6743],\n",
            "         [505.8322, 497.5137, 580.2042, 519.1187, 466.7090, 416.3920, 426.7586,\n",
            "          422.3888, 479.7322, 493.8846, 476.4145],\n",
            "         [427.5733, 412.8251, 497.2418, 634.7846, 527.1572, 395.5178, 410.8884,\n",
            "          396.5306, 408.0461, 467.4788, 427.9248],\n",
            "         [459.5841, 423.1107, 446.7763, 533.1639, 628.8554, 463.3914, 454.5725,\n",
            "          440.2788, 439.2932, 490.6413, 460.3162],\n",
            "         [454.8059, 440.3031, 381.5741, 416.8016, 468.5211, 554.9036, 487.0670,\n",
            "          490.9523, 470.3304, 428.6745, 393.7841],\n",
            "         [376.2431, 401.0482, 399.0394, 382.9548, 413.3607, 452.7289, 477.8914,\n",
            "          427.5911, 534.4189, 400.7283, 359.0747],\n",
            "         [450.5171, 396.8223, 444.7869, 456.3083, 462.7532, 487.3189, 508.1948,\n",
            "          478.9283, 555.4233, 462.2168, 410.2640],\n",
            "         [459.7560, 434.0935, 441.0326, 475.6169, 480.9825, 434.7957, 462.3776,\n",
            "          449.6372, 499.3992, 634.7858, 473.4053],\n",
            "         [477.5047, 448.7300, 423.7500, 453.9153, 457.5359, 407.3749, 419.0585,\n",
            "          404.8521, 445.9359, 469.9598, 645.5428]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[607.3152, 491.2888, 470.2065, 475.3505, 432.8672, 417.6981, 426.3401,\n",
            "          382.2360, 422.9578, 424.1310, 451.0470],\n",
            "         [521.1425, 494.5698, 590.6418, 525.1361, 477.7961, 397.9051, 408.7051,\n",
            "          379.2611, 422.5184, 439.0274, 444.2349],\n",
            "         [436.8927, 397.5356, 493.4030, 616.2386, 516.6750, 410.3887, 406.6411,\n",
            "          357.1539, 393.8878, 421.0408, 403.0074],\n",
            "         [411.7911, 357.8187, 421.4886, 497.3759, 607.0214, 440.8491, 412.3297,\n",
            "          364.7768, 379.8767, 413.1655, 384.8463],\n",
            "         [462.2981, 402.9980, 387.8159, 400.8492, 436.1142, 544.8072, 462.5403,\n",
            "          434.8600, 433.6918, 368.9794, 353.1060],\n",
            "         [384.5591, 381.3798, 410.5137, 379.7262, 398.3518, 455.2465, 468.2005,\n",
            "          424.1794, 515.8380, 361.6673, 334.5383],\n",
            "         [457.7267, 389.1842, 438.7376, 456.9414, 443.3394, 470.0324, 489.8133,\n",
            "          436.3818, 534.6000, 426.3182, 383.8839],\n",
            "         [432.2632, 374.4833, 437.5148, 446.5616, 434.3290, 390.8992, 422.7966,\n",
            "          375.2312, 436.5003, 596.9171, 421.0485],\n",
            "         [488.0298, 424.0452, 446.7606, 480.1557, 433.5559, 356.5185, 382.6623,\n",
            "          344.3047, 387.0267, 456.2423, 617.4497]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[609.5448, 513.8971, 476.9239, 475.7646, 429.4691, 424.5058, 393.9618,\n",
            "          398.9856, 441.6800, 440.8198, 504.5679],\n",
            "         [515.1378, 503.3914, 574.1159, 518.7616, 453.2057, 400.7166, 409.4464,\n",
            "          402.1290, 443.0349, 452.0740, 462.1777],\n",
            "         [447.0637, 425.2589, 493.7746, 604.6759, 503.4437, 363.2833, 398.5288,\n",
            "          365.4066, 392.7502, 431.5482, 461.1195],\n",
            "         [468.6555, 441.7556, 481.4689, 538.3826, 607.1646, 457.6050, 449.8448,\n",
            "          440.7786, 463.6544, 490.5978, 474.0395],\n",
            "         [474.2510, 466.5367, 408.2596, 426.3457, 458.5371, 559.0802, 489.6707,\n",
            "          472.4357, 487.8992, 417.0100, 397.3604],\n",
            "         [404.2321, 438.1317, 435.9070, 391.9001, 416.7671, 479.1069, 495.1868,\n",
            "          444.2974, 538.3155, 397.7418, 362.0125],\n",
            "         [437.5564, 424.2804, 457.6429, 457.7105, 442.4401, 482.7517, 479.9930,\n",
            "          461.6127, 565.9268, 452.5418, 407.8398],\n",
            "         [449.7717, 418.5672, 452.3428, 483.0217, 443.4607, 376.7617, 429.6306,\n",
            "          412.7175, 456.7396, 610.3561, 478.2303],\n",
            "         [479.1290, 433.7232, 427.3536, 479.7210, 422.7316, 372.0162, 382.3037,\n",
            "          362.1734, 413.6383, 446.0249, 664.7178]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[593.1534, 496.8055, 491.0791, 452.2975, 442.9403, 447.2411, 408.1642,\n",
            "          377.2949, 409.5627, 421.1757, 492.4466],\n",
            "         [503.4705, 484.7420, 597.4298, 519.6250, 449.6930, 415.9660, 425.7002,\n",
            "          386.9332, 438.9397, 451.9678, 454.2897],\n",
            "         [447.1515, 432.7942, 500.6702, 629.3864, 535.9756, 442.7534, 426.3727,\n",
            "          380.4746, 423.0582, 451.4979, 457.3503],\n",
            "         [419.7223, 393.5042, 439.9677, 485.1288, 624.8708, 473.7804, 428.0916,\n",
            "          416.3799, 426.0714, 434.3066, 412.4983],\n",
            "         [428.3454, 430.2319, 385.3321, 390.0027, 485.0260, 544.7621, 486.6756,\n",
            "          462.2251, 466.5020, 366.8172, 357.5573],\n",
            "         [399.2012, 415.9274, 454.0499, 413.2791, 473.3362, 492.3633, 510.3612,\n",
            "          465.4527, 555.3947, 406.8218, 387.5005],\n",
            "         [448.5508, 419.3076, 452.3318, 443.3956, 467.3891, 510.9643, 495.2305,\n",
            "          480.4406, 531.8098, 431.9220, 415.1479],\n",
            "         [417.9441, 405.0926, 436.5676, 462.0399, 488.0965, 423.8253, 453.5562,\n",
            "          405.8086, 456.8059, 599.5749, 422.9475],\n",
            "         [475.3408, 440.8901, 439.7957, 445.3347, 456.5329, 409.2737, 393.3296,\n",
            "          368.6723, 404.7976, 455.9496, 630.2748]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[846.4657, 742.3328, 663.4410, 680.6663, 557.6207, 676.0916, 577.3548,\n",
            "          531.6242, 612.8839, 635.9781, 680.7181],\n",
            "         [773.3913, 744.8484, 777.9465, 750.7842, 576.3986, 642.9008, 586.8467,\n",
            "          534.3205, 662.5198, 680.3649, 682.7978],\n",
            "         [775.2344, 742.4458, 760.5793, 868.5494, 643.6876, 673.3889, 604.4189,\n",
            "          572.6911, 669.7235, 710.5353, 712.7029],\n",
            "         [634.3710, 586.7303, 563.0947, 664.5675, 702.1881, 641.5460, 549.3091,\n",
            "          531.0726, 556.9310, 582.6902, 560.6732],\n",
            "         [693.2976, 682.0070, 591.5701, 643.7850, 576.4705, 750.1563, 614.3814,\n",
            "          582.2310, 667.4269, 604.6105, 591.9229],\n",
            "         [627.6168, 650.3977, 618.7896, 633.4938, 559.2552, 648.0547, 616.0252,\n",
            "          562.0801, 710.3525, 599.6531, 551.5183],\n",
            "         [701.5187, 656.0082, 636.3214, 683.0607, 549.7628, 694.2034, 624.3845,\n",
            "          583.6913, 728.6639, 665.9628, 637.2699],\n",
            "         [672.4747, 660.6071, 619.7394, 666.1879, 558.5332, 610.1268, 585.5226,\n",
            "          536.3843, 646.4327, 769.1370, 631.5191],\n",
            "         [727.8646, 664.2015, 628.1857, 693.4730, 563.8564, 625.9223, 558.5623,\n",
            "          508.7440, 614.7107, 646.9003, 833.8127]]])\n",
            " (layer 10 > 0.001) 8 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[882.9351, 715.1603, 668.2336, 660.5616, 670.1950, 680.3168, 672.1047,\n",
            "          663.3947, 698.9757, 664.3457, 709.0106],\n",
            "         [756.2162, 699.1945, 734.1748, 702.5934, 650.9811, 618.3643, 633.7535,\n",
            "          606.6321, 669.5845, 637.2285, 659.8598],\n",
            "         [620.4639, 556.4691, 640.9480, 753.9756, 646.9604, 542.9765, 559.2472,\n",
            "          553.8011, 582.9652, 596.0606, 603.6923],\n",
            "         [616.3457, 546.4172, 578.8003, 629.0638, 736.1943, 598.8837, 607.7186,\n",
            "          585.0616, 616.6524, 606.8407, 581.6501],\n",
            "         [673.5895, 608.8459, 514.5850, 549.9783, 615.2732, 708.2407, 670.5564,\n",
            "          641.2829, 638.5809, 576.5577, 578.9260],\n",
            "         [629.6555, 593.0395, 578.0235, 585.3115, 602.6479, 616.4942, 660.4474,\n",
            "          643.9240, 701.2392, 591.6594, 582.0492],\n",
            "         [721.4424, 622.2407, 609.4674, 654.6141, 650.4247, 665.7475, 667.2252,\n",
            "          676.1094, 749.7223, 669.2347, 669.7552],\n",
            "         [644.1362, 588.3063, 565.2233, 612.8620, 628.1796, 583.7554, 623.8633,\n",
            "          593.1083, 664.4232, 761.1737, 641.2618],\n",
            "         [734.0925, 646.8636, 578.3762, 626.1935, 631.6323, 613.2754, 616.9180,\n",
            "          586.1537, 655.9750, 649.2001, 856.4730]]])\n",
            " (layer 10 > 0.0001) 7 links [(0, 0), (2, 3), (3, 4), (3, 5), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[812.0488, 746.1646, 693.6450, 770.4390, 663.9965, 649.6678, 621.8783,\n",
            "          589.9662, 666.6095, 679.5134, 744.9043],\n",
            "         [686.0854, 685.2206, 748.7119, 750.2381, 624.1030, 558.8531, 574.4711,\n",
            "          517.9947, 610.7119, 641.1630, 686.1398],\n",
            "         [564.8892, 543.8158, 612.0968, 754.2322, 601.3413, 507.9751, 518.6927,\n",
            "          520.4235, 535.4764, 577.0369, 596.4426],\n",
            "         [592.6063, 574.8867, 589.5626, 687.0858, 741.7084, 573.6415, 569.7506,\n",
            "          545.0820, 568.3411, 622.4483, 603.7296],\n",
            "         [641.1066, 624.7689, 559.2621, 670.3318, 641.9197, 676.2184, 633.0450,\n",
            "          616.1642, 636.4802, 620.6352, 598.7617],\n",
            "         [591.9715, 614.2261, 598.5004, 664.4450, 617.3447, 604.0407, 609.3698,\n",
            "          589.4094, 668.8466, 620.0583, 597.1322],\n",
            "         [704.8677, 685.5119, 662.0125, 766.5626, 662.5275, 668.9081, 666.0524,\n",
            "          629.1640, 731.2184, 708.1212, 695.4191],\n",
            "         [551.9656, 545.9397, 543.1084, 639.1995, 592.6608, 534.2267, 546.0856,\n",
            "          531.8799, 582.6262, 717.3890, 608.7926],\n",
            "         [679.3163, 640.7773, 599.9120, 736.3383, 632.1068, 570.8396, 564.6743,\n",
            "          545.4254, 601.1615, 652.1714, 872.0649]]])\n",
            " (layer 10 > 1e-05) 7 links [(0, 0), (1, 2), (3, 4), (3, 5), (5, 3), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[896.8429, 698.3163, 650.7358, 618.0475, 590.9124, 708.7426, 596.8087,\n",
            "          610.7762, 664.5337, 647.2887, 764.9086],\n",
            "         [761.9944, 672.7483, 718.3400, 647.7247, 561.7328, 639.0919, 563.0581,\n",
            "          559.9791, 634.5586, 599.2458, 688.3974],\n",
            "         [679.8447, 579.8896, 657.4258, 758.7473, 642.9316, 630.2292, 566.8452,\n",
            "          550.2766, 626.9929, 621.4927, 650.1636],\n",
            "         [651.7932, 530.1788, 564.9422, 626.2796, 727.4637, 649.7857, 580.9609,\n",
            "          564.9649, 617.9974, 596.1141, 613.9362],\n",
            "         [686.9564, 602.3354, 531.7914, 564.5424, 585.4126, 718.7876, 612.0282,\n",
            "          610.9650, 631.1851, 583.1790, 593.5399],\n",
            "         [552.1608, 522.8436, 519.6559, 529.1201, 535.6164, 594.3769, 535.7794,\n",
            "          537.7260, 644.3850, 546.2258, 512.6447],\n",
            "         [753.9742, 627.2199, 631.5647, 632.3123, 590.2899, 708.6830, 613.4908,\n",
            "          644.9717, 764.6649, 676.5502, 689.4666],\n",
            "         [744.7877, 617.9401, 596.9648, 618.4445, 588.2779, 648.7269, 597.7166,\n",
            "          616.4020, 702.2939, 776.7095, 738.0798],\n",
            "         [746.5668, 579.3351, 568.0060, 612.5748, 557.7037, 624.0678, 528.7169,\n",
            "          533.7214, 622.4770, 636.7764, 841.8417]]])\n",
            " (layer 10 > 1e-06) 7 links [(0, 0), (2, 3), (3, 4), (3, 5), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[826.4487, 759.9408, 655.2419, 656.8979, 613.7185, 670.2944, 597.8745,\n",
            "          621.5121, 681.7622, 654.4487, 771.3226],\n",
            "         [718.8892, 728.6829, 756.7356, 713.5319, 614.1622, 609.9836, 595.4222,\n",
            "          608.7135, 686.3641, 639.3462, 723.3890],\n",
            "         [671.9172, 688.5765, 675.5350, 814.3061, 678.6779, 605.2643, 570.5989,\n",
            "          607.7021, 661.4418, 647.0515, 707.7025],\n",
            "         [589.1321, 575.5943, 550.3712, 645.2581, 721.4400, 627.8722, 558.3430,\n",
            "          570.0884, 597.7519, 604.0679, 595.5821],\n",
            "         [622.3359, 613.3157, 526.7125, 562.5637, 588.7207, 720.1939, 626.1239,\n",
            "          602.4926, 662.1840, 588.6451, 615.0711],\n",
            "         [532.6370, 563.1671, 529.6555, 544.7006, 546.6044, 598.3549, 606.5033,\n",
            "          564.3423, 680.7290, 551.1290, 555.1660],\n",
            "         [608.0743, 599.8030, 573.1467, 624.0042, 586.8253, 638.9327, 604.8486,\n",
            "          631.8659, 708.6418, 645.9742, 638.7914],\n",
            "         [580.2280, 584.7112, 552.1296, 607.7096, 591.1208, 597.9248, 604.9356,\n",
            "          585.1821, 661.8943, 752.4576, 646.6393],\n",
            "         [654.4616, 635.4219, 567.8221, 631.5060, 583.8836, 590.8454, 545.4013,\n",
            "          580.4461, 643.6117, 636.3588, 838.5989]]])\n",
            " (layer 10 > 1e-07) 8 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[801.0900, 732.8694, 721.5595, 660.0065, 671.9519, 622.8058, 595.0989,\n",
            "          586.6572, 723.1680, 668.2715, 711.2424],\n",
            "         [649.8837, 639.0306, 737.0904, 659.1956, 612.2518, 532.8418, 543.5974,\n",
            "          502.0477, 652.0157, 618.9204, 629.6669],\n",
            "         [609.9046, 603.3205, 679.0403, 775.9553, 684.1715, 547.4043, 531.2481,\n",
            "          528.1795, 637.0643, 609.1947, 614.4233],\n",
            "         [578.1103, 552.4234, 602.2328, 619.9728, 735.1044, 561.4818, 527.2554,\n",
            "          520.0267, 601.9271, 583.9869, 549.5124],\n",
            "         [606.1061, 585.3475, 564.7081, 539.4818, 603.0013, 648.8249, 577.0662,\n",
            "          565.7680, 649.9042, 552.1874, 531.1353],\n",
            "         [570.0627, 601.9598, 615.3284, 568.5857, 596.2660, 575.7701, 598.4793,\n",
            "          558.4543, 701.2853, 577.4056, 543.3799],\n",
            "         [636.1942, 631.8214, 657.8905, 611.3759, 616.2419, 592.3476, 590.8234,\n",
            "          583.0356, 728.1890, 664.5776, 609.3796],\n",
            "         [511.5465, 480.6973, 533.8314, 522.2636, 559.9763, 453.8967, 500.4326,\n",
            "          452.1478, 567.5629, 673.3665, 530.7422],\n",
            "         [650.1967, 608.6982, 623.2404, 638.6730, 626.0905, 524.0215, 522.4367,\n",
            "          527.4824, 650.4358, 634.3102, 812.9185]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[845.6478, 769.3870, 714.4337, 659.8080, 661.6385, 656.5179, 608.8948,\n",
            "          607.0035, 719.4767, 687.0430, 713.3923],\n",
            "         [706.6532, 692.1432, 769.5186, 690.9189, 638.1746, 599.1215, 585.3055,\n",
            "          573.0703, 677.1552, 678.8331, 650.5347],\n",
            "         [629.5240, 613.3298, 668.7599, 766.5081, 673.7694, 580.7332, 564.5778,\n",
            "          560.6734, 645.5295, 659.4149, 636.7844],\n",
            "         [619.5602, 600.8319, 611.7634, 654.7385, 759.6239, 604.5071, 572.6653,\n",
            "          566.1854, 628.6818, 644.4568, 629.6376],\n",
            "         [677.3557, 661.5606, 590.1699, 578.8248, 643.7879, 697.5911, 633.5724,\n",
            "          617.9394, 677.3873, 626.7441, 619.4804],\n",
            "         [517.4909, 551.3118, 552.8484, 536.9365, 559.9975, 556.8809, 585.9454,\n",
            "          551.3802, 668.8449, 578.1299, 505.8454],\n",
            "         [619.4587, 596.3195, 589.2414, 603.0695, 616.8561, 620.5501, 608.9250,\n",
            "          599.0814, 719.9789, 652.6556, 579.5389],\n",
            "         [602.0495, 591.2944, 608.2740, 603.8290, 617.4099, 539.2335, 554.0623,\n",
            "          551.2114, 655.8584, 759.8687, 643.9932],\n",
            "         [671.5285, 630.2222, 603.6882, 624.4623, 605.7302, 558.8804, 545.0938,\n",
            "          538.8687, 655.4537, 659.8861, 857.8139]]])\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[872.2524, 809.2565, 728.0703, 662.7225, 706.8242, 748.9853, 632.7372,\n",
            "          685.3042, 710.1595, 738.6153, 819.7609],\n",
            "         [800.3833, 784.2633, 809.8429, 728.5287, 710.4487, 719.3770, 639.5575,\n",
            "          676.2643, 717.7095, 742.8508, 771.4583],\n",
            "         [670.5059, 643.5823, 681.0305, 789.0896, 719.0822, 650.9843, 594.4833,\n",
            "          630.5594, 636.9003, 681.6412, 684.9486],\n",
            "         [673.9547, 652.3156, 620.6606, 699.2587, 781.7762, 700.7606, 613.9522,\n",
            "          664.3539, 660.6490, 683.9344, 693.6161],\n",
            "         [707.7299, 693.9702, 592.1601, 600.9442, 696.2300, 781.4869, 656.2469,\n",
            "          699.3245, 673.1224, 683.0657, 690.7371],\n",
            "         [597.5287, 620.8989, 604.0001, 572.3448, 622.6173, 662.6332, 628.8011,\n",
            "          639.2382, 705.3187, 619.8640, 596.5965],\n",
            "         [623.5331, 597.4951, 596.1859, 594.0676, 639.6932, 693.0159, 629.9402,\n",
            "          629.9357, 691.5248, 660.1137, 611.9958],\n",
            "         [590.0759, 579.6371, 575.7523, 598.1608, 639.7687, 610.8320, 577.9943,\n",
            "          586.9802, 615.6921, 758.7548, 663.0734],\n",
            "         [696.9062, 664.9357, 633.7669, 653.3312, 650.7888, 646.4068, 574.7607,\n",
            "          613.6943, 629.9892, 710.6443, 895.2783]]])\n",
            " (layer 10 > 1e-10) 8 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (4, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94mlove\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[891.7562, 808.2869, 745.5819, 728.2261, 666.9711, 772.4809, 697.5154,\n",
            "          669.9786, 700.0670, 693.4202, 773.8706],\n",
            "         [744.7646, 723.5465, 783.3820, 740.0167, 639.9257, 683.5751, 626.6363,\n",
            "          596.1593, 664.3251, 652.4317, 689.0036],\n",
            "         [692.4241, 650.3625, 701.1558, 823.8856, 679.9720, 665.6244, 613.8947,\n",
            "          605.6501, 629.7068, 632.0858, 676.1045],\n",
            "         [601.9065, 567.6742, 582.0089, 646.2145, 753.8051, 675.5166, 607.6489,\n",
            "          579.7515, 598.1106, 588.9612, 585.5967],\n",
            "         [709.0385, 675.7335, 604.4247, 632.0634, 632.4060, 781.2547, 690.4725,\n",
            "          657.6561, 668.6594, 601.3270, 622.4064],\n",
            "         [664.7319, 654.8970, 653.4059, 660.2977, 624.3228, 710.0251, 673.7487,\n",
            "          648.4108, 722.3951, 624.2582, 629.6495],\n",
            "         [681.6722, 635.6944, 639.4666, 647.7750, 604.8643, 718.3231, 671.9275,\n",
            "          649.8918, 710.7115, 626.1462, 625.6099],\n",
            "         [620.0591, 579.0143, 579.0507, 608.3776, 591.7305, 622.2780, 603.5558,\n",
            "          590.1667, 638.1552, 749.1436, 617.5949],\n",
            "         [742.4453, 681.0692, 631.9033, 686.4940, 606.7278, 666.7499, 605.2576,\n",
            "          576.4655, 638.6523, 648.4417, 873.2371]]])\n",
            " (layer 10 > 1e-11) 9 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (4, 8), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94mlove\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[856.0891, 782.0237, 736.1343, 683.1418, 654.6200, 713.3916, 558.1257,\n",
            "          601.8849, 670.6705, 656.7488, 735.3439],\n",
            "         [753.2531, 757.5986, 811.5620, 729.9366, 643.2952, 642.8969, 519.5948,\n",
            "          555.1602, 663.4338, 628.8910, 699.4511],\n",
            "         [639.7708, 619.4008, 686.5667, 768.8895, 647.0624, 585.0713, 486.3622,\n",
            "          516.9789, 601.3119, 584.5820, 619.8249],\n",
            "         [603.5728, 574.4645, 610.7024, 663.6601, 730.2403, 628.7457, 525.2496,\n",
            "          561.8978, 612.7062, 586.0565, 587.5166],\n",
            "         [646.5172, 626.3463, 575.4384, 591.7859, 614.6064, 734.0051, 586.6452,\n",
            "          626.6373, 658.5697, 573.5864, 562.4160],\n",
            "         [557.1716, 583.2860, 586.5969, 560.6625, 560.9978, 629.9637, 561.0876,\n",
            "          578.4108, 678.7151, 550.1107, 525.9476],\n",
            "         [629.4589, 581.0009, 621.1984, 612.3203, 593.5493, 677.8940, 567.5898,\n",
            "          599.0051, 707.5646, 598.8809, 579.9116],\n",
            "         [616.9968, 600.7186, 586.5808, 607.2334, 588.5187, 602.8038, 501.0692,\n",
            "          529.7752, 622.6414, 716.8718, 620.8015],\n",
            "         [715.2537, 692.1435, 642.2120, 661.7271, 629.3711, 629.3666, 497.6469,\n",
            "          546.3434, 622.6053, 636.6934, 830.5619]]])\n",
            " (layer 10 > 1e-12) 8 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[892.2562, 815.8134, 699.4724, 731.3235, 596.6910, 639.6756, 563.9694,\n",
            "          595.6884, 630.6045, 716.6252, 759.1651],\n",
            "         [727.3184, 713.3620, 755.4990, 732.1772, 590.2867, 577.1473, 541.3678,\n",
            "          537.5701, 579.3893, 669.1669, 680.2746],\n",
            "         [655.8892, 634.1155, 665.4621, 795.8109, 639.7692, 553.1492, 504.9099,\n",
            "          526.3539, 559.4654, 643.9767, 678.5733],\n",
            "         [677.2446, 632.1044, 643.2335, 709.7539, 731.2559, 587.0578, 540.3813,\n",
            "          543.1036, 564.4583, 661.0883, 654.4215],\n",
            "         [702.0080, 667.0206, 555.7896, 623.9556, 561.8276, 665.8195, 585.9401,\n",
            "          583.5443, 573.2569, 606.2809, 589.9919],\n",
            "         [577.5118, 602.3533, 581.9900, 587.5721, 536.8345, 569.9236, 580.3837,\n",
            "          555.1393, 629.8478, 594.7020, 537.6658],\n",
            "         [728.7493, 671.5469, 636.0722, 684.0353, 582.4299, 642.2839, 579.7230,\n",
            "          606.8915, 660.9627, 680.9437, 647.1303],\n",
            "         [649.3264, 634.6915, 609.5215, 658.3329, 575.6001, 574.7659, 556.2975,\n",
            "          549.6541, 593.5058, 770.2961, 670.1812],\n",
            "         [715.7152, 671.5648, 608.6722, 667.4956, 546.2354, 551.8720, 496.9983,\n",
            "          520.7065, 554.5760, 661.4620, 878.5720]]])\n",
            " (layer 10 > 1e-13) 6 links [(0, 0), (1, 2), (2, 3), (3, 4), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n",
            "#prod=torch.Size([1, 9, 11]) tensor([[[872.5362, 750.4929, 676.7936, 662.3152, 602.8489, 626.7104, 538.1873,\n",
            "          628.9301, 639.3040, 665.4546, 729.3972],\n",
            "         [778.6019, 735.4441, 761.9897, 707.9042, 607.4769, 550.0771, 526.2954,\n",
            "          629.8670, 654.1216, 683.2548, 716.6100],\n",
            "         [620.4053, 572.2749, 632.0640, 741.3058, 633.9138, 528.5556, 497.1292,\n",
            "          565.3480, 571.2285, 623.5392, 641.7278],\n",
            "         [544.8709, 480.5258, 511.2535, 573.5462, 687.5975, 528.6171, 486.8203,\n",
            "          528.2490, 528.6023, 560.7724, 542.4628],\n",
            "         [656.8980, 598.5716, 536.8522, 570.8197, 576.8730, 640.1246, 539.1333,\n",
            "          601.6235, 598.9570, 588.1097, 566.6882],\n",
            "         [576.8544, 550.2826, 563.0988, 575.8388, 544.0508, 549.9885, 538.9778,\n",
            "          581.5181, 647.5109, 597.8774, 564.6818],\n",
            "         [668.2200, 582.6813, 577.4406, 618.8859, 583.7879, 618.9885, 551.2355,\n",
            "          634.1112, 698.1573, 652.2968, 625.6075],\n",
            "         [588.0048, 523.8992, 539.7209, 566.1439, 566.0673, 496.5661, 499.6433,\n",
            "          576.8315, 593.9866, 738.9954, 605.8147],\n",
            "         [781.2310, 671.7578, 613.4423, 663.8735, 598.9097, 574.0234, 517.2858,\n",
            "          622.9028, 640.5707, 683.6348, 878.1271]]])\n",
            " (layer 10 > 1e-14) 8 links [(0, 0), (1, 2), (2, 3), (3, 4), (3, 5), (5, 8), (6, 9), (7, 10)] for 'He said : \"I love you \" .' to 'Il a dit : « Je t ' aime » .'\n",
            "\u001b[1m\u001b[94mHe\u001b[0m===\u001b[1m\u001b[91mIl\u001b[0m\n",
            "\u001b[1m\u001b[94msaid\u001b[0m===\u001b[1m\u001b[91mdit\u001b[0m\n",
            "\u001b[1m\u001b[94m:\u001b[0m===\u001b[1m\u001b[91m:\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91m«\u001b[0m\n",
            "\u001b[1m\u001b[94m\"I\u001b[0m===\u001b[1m\u001b[91mJe\u001b[0m\n",
            "\u001b[1m\u001b[94myou\u001b[0m===\u001b[1m\u001b[91maime\u001b[0m\n",
            "\u001b[1m\u001b[94m\"\u001b[0m===\u001b[1m\u001b[91m»\u001b[0m\n",
            "\u001b[1m\u001b[94m.\u001b[0m===\u001b[1m\u001b[91m.\u001b[0m\n",
            ".\n",
            "\n"
          ]
        }
      ]
    }
  ]
}